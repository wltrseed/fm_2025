{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdxTLzCPyxE3"
      },
      "source": [
        "Стандартные библиотеки Python :\n",
        "os, sys, collections и другие являются мощным инструментом, которым нужно и полезно уметь пользоваться.\n",
        "\n",
        "Ресурсы к ознакомлению:\n",
        "\n",
        "sys -- https://docs.python.org/3/library/sys.html\n",
        "\n",
        "os -- https://docs.python.org/3/library/os.html\n",
        "\n",
        "collections -- https://docs.python.org/3/library/collections.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuTZ5-yiyxE4"
      },
      "source": [
        "#### COLLECTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1V3UrdwyxE4",
        "outputId": "b1d399c8-150a-4f68-e703-5bbaf0ac77e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deque\n",
            "defaultdict\n",
            "OrderedDict\n",
            "namedtuple\n",
            "Counter\n",
            "ChainMap\n",
            "UserDict\n",
            "UserList\n",
            "UserString\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Начнем с collections. Библиотека хранит в себе специальные контейнеры,\n",
        "    расширяющие классический список контейнеров: списков, кортежей и словарей.\n",
        "\"\"\"\n",
        "import collections\n",
        "\"\"\"\n",
        "    Посмотреть содержащиеся полезные модули можно, написав функцию ниже одной строкой.\n",
        "\"\"\"\n",
        "print('\\n'.join(list(filter(lambda x: not x.startswith('_') and x != 'abc', collections.__dict__.keys()))))\n",
        "# содержательно эта строка станет понятна по мере освоения курса\n",
        "# она неявно содержит в себе концепции list comprehension, а также парадигмы функционального программирования\n",
        "# и в целом демонстрирует лаконичность и эффективность инструментов языка python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnAL4BYhyxE4",
        "outputId": "182337f6-d95a-40fb-9348-35a3b19a3b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CallOption(strike=100, expiration_date='2026-01-01') <class '__main__.CallOption'>\n",
            "100 <class 'int'> 2026-01-01 <class 'str'>\n",
            "Достаем словарь: {'strike': 100, 'expiration_date': '2026-01-01'} <class 'dict'>\n",
            "Создаем новый именованный кортеж: CallOption(strike=200, expiration_date='2026-01-01')\n",
            "('strike', 'expiration_date') <class 'tuple'>\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    Начнем с рассмотрения namedtuple. Это именованный кортеж, который то же самое, что и кортеж,\n",
        "    но допускает обращение к своим полям по имени. Более точно, это специальный тип класса с реализованным дандер методом '__repr__()'\n",
        "'''\n",
        "from collections import namedtuple\n",
        "from typing import NamedTuple # нужна для указания типа, или в качестве указания как родительского класса при создании дочернего\n",
        "\n",
        "CallOption = namedtuple('CallOption', ['strike', 'expiration_date'])\n",
        "\n",
        "my_option: CallOption = CallOption(strike=100, expiration_date='2026-01-01')\n",
        "print(my_option, type(my_option))\n",
        "print(my_option.strike, type(my_option.strike), my_option.expiration_date, type(my_option.expiration_date))\n",
        "\n",
        "# my_option.strike = 101 # AttributeError: can't set attribute\n",
        "'''\n",
        "    Для работы с именованными кортежами полезно пользоваться некоторыми методами\n",
        "'''\n",
        "# namedtuple._asdict() -- представляет объект класса как словарь\n",
        "print('Достаем словарь:', my_option._asdict(), type(my_option._asdict()))\n",
        "\n",
        "# namedtuple._replace -- возвращает новый экземляр  замененным полем\n",
        "print('Создаем новый именованный кортеж:', my_option._replace(strike=200))\n",
        "\n",
        "# namedtuple._fields -- получить кортеж строк полей\n",
        "print(my_option._fields, type(my_option._fields))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVTKizkayxE4",
        "outputId": "b03c260f-66df-4324-c1a4-c875093b2c14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12], maxlen=10) , ограничен по длине  10 \n",
            "\n",
            "Убрать элемент слева: 3 , в очереди останется: deque([4, 5, 6, 7, 8, 9, 10, 11, 12], maxlen=10) , длина  9\n",
            "Убрать элемент справа: 12 , в очереди останется: deque([4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  8 \n",
            "\n",
            "Добавить элемент слева: None , в очереди станет: deque([0, 4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  9\n",
            "Добавить элемент справа: None , в очереди станет: deque([0, 4, 5, 6, 7, 8, 9, 10, 11, 0], maxlen=10) , длина  10\n",
            "Добавить элемент слева: None , в очереди станет: deque([0, 0, 4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  10\n",
            "Добавить элемент справа: None , в очереди станет: deque([0, 4, 5, 6, 7, 8, 9, 10, 11, 0], maxlen=10) , длина  10\n",
            "Добавить еще элемент слева: None , в очереди станет: deque([0, 0, 4, 5, 6, 7, 8, 9, 10, 11], maxlen=10) , длина  10\n",
            "Добавить еще элемент слева: None , в очереди станет: deque([0, 0, 0, 4, 5, 6, 7, 8, 9, 10], maxlen=10) , длина  10\n",
            "deque([0, 0, 0, 4, 5, 6, 7, 8, 9, 10], maxlen=10) \n",
            "\n",
            "используем rotate(2): None , получаем: deque([9, 10, 0, 0, 0, 4, 5, 6, 7, 8], maxlen=10)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Далее deque. Это список с эффективной реализацией добавления и извлечения элементов.\n",
        "    В соответствии с описанием в документации:\n",
        "        Дек это обобщение стека и очереди. Он потоко-безопасный (thread-safe, то есть его можно параллелить\n",
        "        на уровне потоков без опасения измененения объекта со стороны другого потока, здравствуй impute и lock),\n",
        "        эффективный по памяти и требует О(1) времени на добавление и извлечение элемента с начала и конца списка.\n",
        "\"\"\"\n",
        "from collections import deque\n",
        "\n",
        "my_deque = deque(maxlen=10)\n",
        "_ = [my_deque.append(i) for i in range(13)]\n",
        "print(my_deque, ', ограничен по длине ', len(my_deque), '\\n')\n",
        "\n",
        "print('Убрать элемент слева:', my_deque.popleft(), ', в очереди останется:', my_deque, ', длина ', len(my_deque))\n",
        "print('Убрать элемент справа:', my_deque.pop(), ', в очереди останется:', my_deque, ', длина ', len(my_deque), '\\n')\n",
        "\n",
        "print('Добавить элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
        "print('Добавить элемент справа:', my_deque.append(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
        "print('Добавить элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
        "print('Добавить элемент справа:', my_deque.append(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
        "print('Добавить еще элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
        "print('Добавить еще элемент слева:', my_deque.appendleft(0), ', в очереди станет:', my_deque, ', длина ', len(my_deque))\n",
        "'''\n",
        "    Очередь позволяет эффективно осуществлять операции вставки и изъятия объектов в начале и в конце списка.\n",
        "    И кроме того в ней встроена защита от дурака, которая не позволит создавать бесконечно большой список.\n",
        "'''\n",
        "print(my_deque * 2 ** 10, '\\n') # мы можем бесконечно долго из-за ошибки в коде нарашивать длину списка, но не сможем для очереди\n",
        "'''\n",
        "    deque поддерживает многие операции, доступные list:\n",
        "    insert, clear, copy, count, extend, remove, reverse\n",
        "    Есть свой метод rotate(n=1), который по принципу RR(RoundRobin) сдвигает все элементы на n вправо (n < 0 -- влево)\n",
        "'''\n",
        "print('используем rotate(2):', my_deque.rotate(2), ', получаем:', my_deque)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjasXMblyxE5",
        "outputId": "e119981e-ab66-46c6-d130-b91a2ed3ccf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "missing_value\n",
            "missing_value\n",
            "arbitraty_value_inserted_right_here\n",
            "defaultdict(<class 'list'>, {'fridge': ['egg', 'steak', 'butter'], 'pocket': ['money']})\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    следующий объект -- defaultdict. Он расширяет обыкновенный словарь, добавляя метод,\n",
        "    который вызывается каждый раз при отсуствии ключа, по которому произошло обращение.\n",
        "    При создании словаря с дефолтным значением в случае неуказания этого дефолтного значения (аргумент default_factory)\n",
        "    он работает как обычный словарь. Если default_factory указан, то по указанному отсутствующему ключу вызывается default_factory\n",
        "    Сигнатура такая : defaultdict(default_factory: Callable[[None], object])\n",
        "    При этом\n",
        "'''\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "my_default_dict = defaultdict()\n",
        "# my_default_dict['0'] # KeyError\n",
        "\n",
        "# 1 способ\n",
        "my_default_dict = defaultdict(lambda: 'missing_value')\n",
        "print(my_default_dict['0'])\n",
        "\n",
        "# 2 способ\n",
        "def return_dafault_value():\n",
        "    return 'missing_value'\n",
        "\n",
        "my_default_dict = defaultdict(return_dafault_value)\n",
        "print(my_default_dict['0'])\n",
        "\n",
        "# 3 способ\n",
        "def return_dafault_value(value):\n",
        "    return lambda: value\n",
        "\n",
        "my_default_dict = defaultdict(return_dafault_value('arbitraty_value_inserted_right_here'))\n",
        "print(my_default_dict['0'])\n",
        "\n",
        "# другие варианты\n",
        "my_default_dict = defaultdict(list) # дефолтом ставим список\n",
        "my_default_dict['fridge'].append('egg')\n",
        "my_default_dict['fridge'].append('steak')\n",
        "my_default_dict['fridge'].append('butter')\n",
        "my_default_dict['pocket'].append('money')\n",
        "print(my_default_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZhwfGwPyxE5",
        "outputId": "3c109699-6264-4abf-df75-b801eadd7a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Упорядоченный словарь: OrderedDict([('a', None), ('b', None), ('c', None), ('d', None), ('e', None)]) <class 'collections.OrderedDict'>\n",
            "Переупорядочили ключи: acdeb\n",
            "Переупорядочили ключи сноав: bacde\n",
            "Текущий порядок: bacde , вытащим последний добавленный элемент (LIFO): ('e', None)\n",
            "Текущий порядок: bacd , вытащим первый добавленный элемент (FIFO): ('b', None)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    OrderedDict -- это словарь, который помнит порядок добавления ключей. Начиная с python 3.7 это умеет и дефолтный словарь (dict, не путать с defaultdict)\n",
        "    Так что по большому счету он не настолько актуален. Однако если вам нужно в явном виде донести важную идею вашего кода,\n",
        "    то использование OrderedDict оправдано вашими целями\n",
        "'''\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "my_ordered_dict: OrderedDict = OrderedDict.fromkeys('abcde')\n",
        "print('Упорядоченный словарь:', my_ordered_dict, type(my_ordered_dict))\n",
        "my_ordered_dict.move_to_end('b')\n",
        "print('Переупорядочили ключи:', ''.join(my_ordered_dict))\n",
        "\n",
        "my_ordered_dict.move_to_end('b', last=False)\n",
        "print('Переупорядочили ключи сноав:', ''.join(my_ordered_dict))\n",
        "\n",
        "print('Текущий порядок:', ''.join(my_ordered_dict), ', вытащим последний добавленный элемент (LIFO):', my_ordered_dict.popitem())\n",
        "print('Текущий порядок:', ''.join(my_ordered_dict), ', вытащим первый добавленный элемент (FIFO):', my_ordered_dict.popitem(last=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7x8xKgKyxE5",
        "outputId": "e22770b3-02d6-4959-ed02-1e312594b17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChainMap({'a': 1, 'b': 2, 'c': 3}, {'color': 'yellow', 'size': 10}, {'date': '2025-01-01', 'time': '16:00'}) <class 'collections.ChainMap'>\n",
            "Ссылаемся на объект из 3го словаря: 16:00\n",
            "date 2025-01-01\n",
            "time 16:00\n",
            "color yellow\n",
            "size 10\n",
            "a 1\n",
            "b 2\n",
            "c 3\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    ChainMap -- подкласс словаря, который объединяет несколько отдельных словарей в один общий.\n",
        "'''\n",
        "\n",
        "from collections import ChainMap\n",
        "\n",
        "my_dict_1 = dict(a=1, b=2, c=3)\n",
        "my_dict_2 = dict(color='yellow', size=10)\n",
        "my_dict_3 = dict(date='2025-01-01', time='16:00')\n",
        "\n",
        "chain_map : ChainMap = ChainMap(my_dict_1, my_dict_2, my_dict_3)\n",
        "print(chain_map, type(chain_map))\n",
        "print('Ссылаемся на объект из 3го словаря:', chain_map['time'])\n",
        "# print('Ссылаемся на объект, которого нет:', chain_map['weather']) # KeyError\n",
        "# мы можем проитерироваться по всем объектам в chain'e\n",
        "for key, value in chain_map.items():\n",
        "    print(key, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68CAJRpryxE5",
        "outputId": "8f7f97e3-97e3-408c-a5b5-73ad95a4b085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Счетчик: Counter({1: 4, 0: 3, 2: 2, 3: 2, 5: 1}) <class 'collections.Counter'>\n",
            "Два самых частых числа (число, кол-во): [(1, 4), (0, 3)]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    Последний рассматриваемый -- Counter -- объект, который парсит итерируемый объект на тему повторяющихся элементов\n",
        "    и формирует словарь, в котором ключами являются уникальные элементы входного списка, а значениями их количество.\n",
        "'''\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "my_counter : Counter = Counter([0,1,2,3,3,2,1,1,1,0,5,0])\n",
        "print('Счетчик:', my_counter, type(my_counter))\n",
        "\n",
        "# дополнительно можно посмотреть наиболее часто встречающиеся объекты\n",
        "print('Два самых частых числа (число, кол-во):', my_counter.most_common(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SiCLzY-yxE5"
      },
      "source": [
        "#### SYS and OS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6mut5tDyxE5",
        "outputId": "7363720e-e096-4d80-8078-05b92cffe03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "abc, sys, st, GenericAlias, name, linesep, stat, access, chdir, chmod, getcwd, getcwdb, link, listdir, lstat, mkdir, readlink, rename, replace, rmdir, symlink, system, umask, unlink, remove, utime, times, execv, execve, spawnv, spawnve, getpid, getppid, getlogin, kill, startfile, waitpid, open, close, closerange, device_encoding, dup, dup2, lseek, read, write, fstat, isatty, pipe, ftruncate, truncate, putenv, unsetenv, strerror, fsync, abort, urandom, get_terminal_size, cpu_count, get_inheritable, set_inheritable, get_handle_inheritable, set_handle_inheritable, scandir, fspath, waitstatus_to_exitcode, environ, F_OK, R_OK, W_OK, X_OK, TMP_MAX, O_RDONLY, O_WRONLY, O_RDWR, O_APPEND, O_CREAT, O_EXCL, O_TRUNC, O_BINARY, O_TEXT, O_NOINHERIT, O_SHORT_LIVED, O_TEMPORARY, O_RANDOM, O_SEQUENTIAL, EX_OK, P_WAIT, P_NOWAIT, P_NOWAITO, P_OVERLAY, P_DETACH, error, stat_result, statvfs_result, terminal_size, DirEntry, times_result, uname_result, path, curdir, pardir, sep, pathsep, defpath, extsep, altsep, devnull, supports_dir_fd, supports_effective_ids, supports_fd, supports_follow_symlinks, SEEK_SET, SEEK_CUR, SEEK_END, makedirs, removedirs, renames, walk, execl, execle, execlp, execlpe, execvp, execvpe, get_exec_path, MutableMapping, Mapping, getenv, supports_bytes_environ, fsencode, fsdecode, spawnl, spawnle, popen, fdopen, PathLike, add_dll_directory\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    библиотека os позволяет работать с некоторым функционалом операционной системы,\n",
        "    которой вы пользуетесь. Как и ранее для более полного ознакомления со всем функционалом рекомендуется читать документацию.\n",
        "'''\n",
        "\n",
        "import os\n",
        "print(', '.join(list(filter(lambda x: not x.startswith('_'), os.__dict__.keys()))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "098oNiQuyxE5"
      },
      "outputs": [],
      "source": [
        "path = None\n",
        "\n",
        "# environ содержит словарь с переменными окружения\n",
        "os.environ\n",
        "\n",
        "# getlogin возвращает имя пользователя\n",
        "os.getlogin()\n",
        "\n",
        "# getpid getppid -- id процесса и id его родительского процесса\n",
        "os.getpid()\n",
        "os.getppid()\n",
        "\n",
        "# os.chmod(path, mode, ...) -- установить мод(режим) для файла по пути path\n",
        "\n",
        "# вернуть текущую директорию\n",
        "os.getcwd()\n",
        "\n",
        "# вернуть список файлов в директории\n",
        "os.listdir()\n",
        "\n",
        "# создает директорию по указанному пути path;\n",
        "# если аргумент 'exist_ok' = True , то функция в случае существования директории не поднимет ошибку, если False -- FileExistsError\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# remove / unlink удаляет файл по указанному пути; если указать директорию, будет выдана ошибка OSError\n",
        "os.remove(path)\n",
        "os.unlink(path)\n",
        "\n",
        "# remodirs удаляет директорию по указанному пути; в случае ошибки выдает OSError\n",
        "os.remodirs(path)\n",
        "\n",
        "# переименовать src файл/директорию в dst\n",
        "os.rename(src=None, dst=None)\n",
        "\n",
        "# scandir возвращает итератор объектов, расположенных по пути path\n",
        "os.scandir(path)\n",
        "\n",
        "# возвращает количество логических процессоров в системе\n",
        "os.cpu_count()\n",
        "\n",
        "#####     os.path     #####\n",
        "\n",
        "# abspath возвращает абсолютный путь к указанному относительному пути\n",
        "os.path.abspath('.')\n",
        "\n",
        "# вовзращает имя конечной точки указанного пути\n",
        "os.path.basename(path)\n",
        "\n",
        "# exists проверяет существование директории или файла по указанному пути и возрвращает True или False\n",
        "os.path.exists(path)\n",
        "\n",
        "# возвращают время\n",
        "os.path.getatime('.') # посещения файла/директории\n",
        "os.path.getmtime('.') # изменения файла/директории\n",
        "os.path.getctime('.') # создания файла/директории\n",
        "\n",
        "# вовзращает размер файла/директории в байтах\n",
        "os.path.getsize(path)\n",
        "\n",
        "# по-умному конкатенирует части путей в один\n",
        "os.path.join(path, *paths)\n",
        "\n",
        "# нормализует путь: удаляет ненужные/кривые символы\n",
        "os.path.normpath(path)\n",
        "\n",
        "# разбивает входную сроку-путь на (head, tail), tail последний файл/директория в пути\n",
        "os.path.split(path)\n",
        "\n",
        "# разбивает входную сроку-путь на путь и расширение файла\n",
        "os.path.splitext('somebody/once/told.me')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9JQnksdyxE6",
        "outputId": "1e92c312-f36d-4fad-fb19-b635c4323a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "addaudithook, audit, breakpointhook, displayhook, exception, exc_info, excepthook, exit, getdefaultencoding, getallocatedblocks, getfilesystemencoding, getfilesystemencodeerrors, getrefcount, getrecursionlimit, getsizeof, getwindowsversion, intern, is_finalizing, setswitchinterval, getswitchinterval, setprofile, getprofile, setrecursionlimit, settrace, gettrace, call_tracing, set_coroutine_origin_tracking_depth, get_coroutine_origin_tracking_depth, set_asyncgen_hooks, get_asyncgen_hooks, unraisablehook, get_int_max_str_digits, set_int_max_str_digits, modules, stderr, version, hexversion, api_version, copyright, platform, maxsize, float_info, int_info, hash_info, maxunicode, builtin_module_names, stdlib_module_names, byteorder, dllhandle, winver, version_info, implementation, flags, float_repr_style, thread_info, meta_path, path_importer_cache, path_hooks, path, executable, prefix, base_prefix, exec_prefix, base_exec_prefix, platlibdir, pycache_prefix, argv, orig_argv, warnoptions, dont_write_bytecode, stdin, stdout, ps1, ps2, ps3\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    библиотека sys позволяет работать с некоторым функционалом интерпретатора.\n",
        "'''\n",
        "\n",
        "import sys\n",
        "print(', '.join(list(filter(lambda x: not x.startswith('_'), sys.__dict__.keys()))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIY2B1s5yxE6"
      },
      "outputs": [],
      "source": [
        "# argv возвращает аргументы скрипта, [0] элемент это имя файла скрипта\n",
        "sys.argv\n",
        "\n",
        "# содержит copyright\n",
        "sys.copyright\n",
        "\n",
        "# очищает кеш интерпретатора\n",
        "sys._clear_type_cache() # до python 3.13\n",
        "# sys._clear_internal_caches() # python 3.13+\n",
        "\n",
        "#  sys.exception() возвращает пойманную в 'except' ошибку; вне конструкции возвращает None (то есть ничего)\n",
        "try:\n",
        "    _ = 0 / 0\n",
        "except:\n",
        "    exception = sys.exception()\n",
        "\n",
        "# возвращает SystemExit exception, сигнализирующий о завершении выполнения интерпретатора\n",
        "# sys.exit()\n",
        "\n",
        "# возвращает количество блоков памяти, занятых интерпретатором\n",
        "sys.getallocatedblocks()\n",
        "\n",
        "# возвращает предел рекурсии в интерпретаторе\n",
        "sys.getrecursionlimit()\n",
        "# sys.setrecursionlimit(N) # устанавливает лимит на рекурсию\n",
        "\n",
        "# возвращает размер объекта в байтах\n",
        "sys.getsizeof( 0 )\n",
        "\n",
        "# возвращает глубину вложенных корутин\n",
        "sys.get_coroutine_origin_tracking_depth()\n",
        "\n",
        "# список всех текущих модулей\n",
        "sys.modules.keys()\n",
        "\n",
        "# версия интерпретатора\n",
        "sys.version\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpch7lmryxE6"
      },
      "source": [
        "#### TYPING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCa2jHoiyxE6",
        "outputId": "daf0cd05-b37b-4a24-e097-adc45ca33325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ABCMeta, AbstractSet, Annotated, Any, AnyStr, AsyncContextManager, AsyncGenerator, AsyncIterable, AsyncIterator, Awaitable, BinaryIO, ByteString, CT_co, Callable, ChainMap, ClassVar, Collection, Concatenate, Container, ContextManager, Coroutine, Counter, DefaultDict, Deque, Dict, EXCLUDED_ATTRIBUTES, Final, ForwardRef, FrozenSet, Generator, Generic, GenericAlias, Hashable, IO, ItemsView, Iterable, Iterator, KT, KeysView, List, Literal, LiteralString, Mapping, MappingView, Match, MethodDescriptorType, MethodWrapperType, MutableMapping, MutableSequence, MutableSet, NamedTuple, NamedTupleMeta, Never, NewType, NoReturn, NotRequired, Optional, OrderedDict, ParamSpec, ParamSpecArgs, ParamSpecKwargs, Pattern, Protocol, Required, Reversible, Self, Sequence, Set, Sized, SupportsAbs, SupportsBytes, SupportsComplex, SupportsFloat, SupportsIndex, SupportsInt, SupportsRound, T, TYPE_CHECKING, T_co, T_contra, Text, TextIO, Tuple, Type, TypeAlias, TypeAliasType, TypeGuard, TypeVar, TypeVarTuple, TypedDict, Union, Unpack, VT, VT_co, V_co, ValuesView, WrapperDescriptorType, abstractmethod, assert_never, assert_type, cast, clear_overloads, collections, contextlib, copyreg, dataclass_transform, defaultdict, final, functools, get_args, get_origin, get_overloads, get_type_hints, io, is_typeddict, no_type_check, no_type_check_decorator, operator, overload, override, re, reveal_type, runtime_checkable, stdlib_re, sys, types, warnings\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    В общем, строгая типизация и аннотирование вашего кода значительно упростят\n",
        "    всю дальнейшую работу с ним. Как вам, так и другим, кто будет его читать.\n",
        "'''\n",
        "\n",
        "import typing\n",
        "print(', '.join(sorted(list(filter(lambda x: not x.startswith('_'), typing.__dict__.keys())))))\n",
        "\n",
        "'''\n",
        "    Вам желательно запомнить некоторые наиболее часто употребляемые типы.\n",
        "    Касательно остальных было неплохо их хотя бы знать, чтобы при случае вы могли ими воспользоваться.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fue8e7uxyxE6"
      },
      "source": [
        "#### SERIALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdc_rMrFyxE6",
        "outputId": "a13766b3-cb7b-4590-e6f6-4890a2aca34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, default write! \n",
            "\n",
            "Hello, json! \n",
            "\n",
            "Hello, dill|pickle|cloudpickle! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "wikipedia\n",
        "    Сериализация (в программировании) — процесс перевода структуры данных в битовую последовательность.\n",
        "    Обратной к операции сериализации является операция десериализации (структуризации) —\n",
        "        создание структуры данных из битовой последовательности.\n",
        "    Мы будем ссылаться на сериализацию как на возможность создания и сохранения файла\n",
        "    из некоторого объекта python.\n",
        "    Есть несколько библиотек, которые позволяют сериализовать некоторый объект.\n",
        "    Если это dataframe, то его можно сериализовать в parquet, csv и другие форматы, предусмотренные библиотекой.\n",
        "    Если это некоторая строка, словарь, список -- можно использовать json\n",
        "    Если это какой-то произвольный объект (любой, в том числе и из вышеперечисленных) --\n",
        "        его можно сохранить в виде бинарного файла. Библиотеки: dill, cloudpickle, pickle\n",
        "        В реальности, разумно ограничиться одной библиотекой. Ознакомьтесь с каждой из списка выше\n",
        "'''\n",
        "\n",
        "import json, cloudpickle, pickle, dill\n",
        "\n",
        "# В общем случае, для работы с файлами используют контекстный менеджер with\n",
        "# Он гарантирует, что вне его блока кода файл корректно будет закрыт\n",
        "\n",
        "# default'ная запись и чтение текстового файла\n",
        "with open('somefile.txt', 'w') as file: # первый аргумент - имя файла, второй режим использования ('w' - запись, 'r' - чтение)\n",
        "    file.write('Hello, default write!')\n",
        "with open('somefile.txt', 'r') as file:\n",
        "    line = file.read()\n",
        "    print(line, '\\n')\n",
        "\n",
        "# сериализация с помощью json\n",
        "with open('somefile.json', 'w') as file:\n",
        "    json.dump('Hello, json!', file)\n",
        "with open('somefile.json', 'r') as file:\n",
        "    line = json.load(file)\n",
        "    print(line, '\\n')\n",
        "\n",
        "# сериализация с помощью dill, pickle, cloudpickle\n",
        "with open('somefile.pickle', 'wb') as file: # для бинарных файлов режим доступа нужно писать 'wb', 'rb' что значит 'binary'\n",
        "    dill.dump('Hello, dill|pickle|cloudpickle!', file)\n",
        "    pickle.dump('Hello, dill|pickle|cloudpickle!', file)\n",
        "    cloudpickle.dump('Hello, dill|pickle|cloudpickle!', file)\n",
        "with open('somefile.pickle', 'rb') as file:\n",
        "    line = dill.load(file)\n",
        "    line = pickle.load(file)\n",
        "    line = cloudpickle.load(file)\n",
        "    print(line, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFxkxKHpyxE6",
        "outputId": "54f58851-642e-4c19-92ca-f3db491c2a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, world!\n",
            "\n",
            "LinearRegression() LinearRegression()\n",
            "\n",
            "Defined function\n"
          ]
        }
      ],
      "source": [
        "# вы можете сериализовать почти любой объект и его состояние\n",
        "\n",
        "# class\n",
        "class ToDemonstrate:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def print_hello(self):\n",
        "        print('Hello, world!')\n",
        "\n",
        "my_class = ToDemonstrate()\n",
        "\n",
        "with open('demonstration_cls.pkl', 'wb') as f:\n",
        "    cloudpickle.dump(my_class, f)\n",
        "with open('demonstration_cls.pkl', 'rb') as f:\n",
        "    new_read_class = cloudpickle.load(f)\n",
        "new_read_class.print_hello()\n",
        "print()\n",
        "\n",
        "# объект из библиотеки, например, объект линейной регресии, который тоже класс\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "with open('not_fitted_lr.pkl', 'wb') as f:\n",
        "    cloudpickle.dump(lr, f)\n",
        "with open('not_fitted_lr.pkl', 'rb') as f:\n",
        "    new_read_lr = cloudpickle.load(f)\n",
        "print(lr, new_read_lr)\n",
        "print()\n",
        "\n",
        "# фунцию (но не анонимную lambda функцию!)\n",
        "def to_save():\n",
        "    print('Defined function')\n",
        "with open('my_func.pkl', 'wb') as f:\n",
        "    cloudpickle.dump(to_save, f)\n",
        "with open('my_func.pkl', 'rb') as f:\n",
        "    new_read_func = cloudpickle.load(f)\n",
        "new_read_func()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IKe81sSyxE6"
      },
      "source": [
        "#### ЗАДАЧИ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvknseGcyxE6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "    Ниже вам будут предложены задачи для освоения материалов.\n",
        "    Собственно, первая и параллельная задача:\n",
        "        Все объекты, которые вы создадите нужно упаковать в виде файлов (то есть сериализовать).\n",
        "        По расширению файла должно быть понятно, как его прочитать.\n",
        "        Дополнительно вам нужно узнать как сохранять файлы в формате .rar, .zip, .tar.gz\n",
        "            и тоже сохранить файлы в этих форматах.\n",
        "\n",
        "    Требования к написанию кода: структура, читаемость, строгая типизация и аннотирования.\n",
        "    Код должен быть очевиден, понятен, структурирован.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "DwyPalfeyxE6",
        "outputId": "6f121ed5-fbce-4fcb-be4b-4912dbddf7ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Все автомобили:\n",
            "Toyota Camry - А123ВС77\n",
            "Honda Civic - В456ОР78\n",
            "BMW X5 - Е789КХ77\n",
            "Lada Vesta - М321ТУ78\n",
            "Kia Rio - Р654НС77\n",
            "Kia Rio2 - Р654НС79\n",
            "Kia Rio3 - Р654НС73\n",
            "Kia Rio4 - Р654НС70\n",
            "Kia Rio5 - Р654НС71\n",
            "\n",
            "Операции со стоянкой:\n",
            "Припарковали: Р654НС70\n",
            "Уехал: Р654НС70\n",
            "Припарковали: В456ОР78\n",
            "Уехал: В456ОР78\n",
            "Припарковали: В456ОР78\n",
            "Уехал: В456ОР78\n",
            "Припарковали: Р654НС77\n",
            "Припарковали: А123ВС77\n",
            "\n",
            "На стоянке осталось 2 машин:\n",
            "1. Kia Rio - Р654НС77 - Зеленый\n",
            "2. Toyota Camry - А123ВС77 - Красный\n",
            "\n",
            "Статистика по маркам:\n",
            "Kia: 1 машин\n",
            "Toyota: 1 машин\n"
          ]
        }
      ],
      "source": [
        "# Реализуйте простую модель стоянки.\n",
        "# 1) Скажем, ваши автомобили это именованные кортежи, с указанием марки автомобиля, модели, гос.номера и цвета\n",
        "# 2) Сама стоянка это двусторонняя очередь (deque)\n",
        "#   Представим, что у нас нет коллизий, и если места на стоянке нет, то виртуально вызывается эвакуатор и убирает самый крайний автомобиль (как и работает deque)\n",
        "# 3) Создайте набор автомобилей и в случайном порядке добавляйте/удаляйте их с автостоянки.\n",
        "# 4) Посчитайте, сколько и каких автомобилей осталось на автостоянке.\n",
        "\n",
        "from collections import deque, namedtuple\n",
        "import random\n",
        "\n",
        "Car = namedtuple('Car', ['brand', 'model', 'license_plate', 'color'])\n",
        "\n",
        "parking = deque(maxlen=3)  # 3 машины\n",
        "\n",
        "cars = [\n",
        "    Car('Toyota', 'Camry', 'А123ВС77', 'Красный'),\n",
        "    Car('Honda', 'Civic', 'В456ОР78', 'Синий'),\n",
        "    Car('BMW', 'X5', 'Е789КХ77', 'Черный'),\n",
        "    Car('Lada', 'Vesta', 'М321ТУ78', 'Белый'),\n",
        "    Car('Kia', 'Rio', 'Р654НС77', 'Зеленый'),\n",
        "    Car('Kia', 'Rio2', 'Р654НС79', 'Зеленый'),\n",
        "    Car('Kia', 'Rio3', 'Р654НС73', 'Зеленый'),\n",
        "    Car('Kia', 'Rio4', 'Р654НС70', 'Зеленый'),\n",
        "    Car('Kia', 'Rio5', 'Р654НС71', 'Зеленый')\n",
        "]\n",
        "\n",
        "print(\"Все автомобили:\")\n",
        "for car in cars:\n",
        "    print(f\"{car.brand} {car.model} - {car.license_plate}\")\n",
        "\n",
        "operations = ['park', 'remove'] * 5\n",
        "random.shuffle(operations)\n",
        "\n",
        "print(\"\\nОперации со стоянкой:\")\n",
        "for operation in operations:\n",
        "    if operation == 'park' and cars:\n",
        "        car = random.choice(cars)\n",
        "        if len(parking) >= parking.maxlen:\n",
        "            removed_car = parking.popleft()\n",
        "            print(f\"Эвакуировали: {removed_car.license_plate}\")\n",
        "\n",
        "        parking.append(car)\n",
        "        print(f\"Припарковали: {car.license_plate}\")\n",
        "\n",
        "    elif operation == 'remove' and parking:\n",
        "        car = random.choice(list(parking))\n",
        "        parking.remove(car)\n",
        "        print(f\"Уехал: {car.license_plate}\")\n",
        "\n",
        "# 5) Результат\n",
        "print(f\"\\nНа стоянке осталось {len(parking)} машин:\")\n",
        "for i, car in enumerate(parking, 1):\n",
        "    print(f\"{i}. {car.brand} {car.model} - {car.license_plate} - {car.color}\")\n",
        "\n",
        "brands = {}\n",
        "for car in parking:\n",
        "    brands[car.brand] = brands.get(car.brand, 0) + 1\n",
        "\n",
        "print(\"\\nСтатистика по маркам:\")\n",
        "for brand, count in brands.items():\n",
        "    print(f\"{brand}: {count} машин\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qri1MOhWyxE7",
        "outputId": "2cad2405-e969-47b8-95b8-bcf362bdaf04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Добавлено: Иванов - мебель - дубовый стол\n",
            "Добавлено: Иванов - мебель - кресло\n",
            "Добавлено: Петров - картины - портрет императора\n",
            "\n",
            "Поиск предметов категории 'мебель':\n",
            "   Иванов: дубовый стол, кресло\n"
          ]
        }
      ],
      "source": [
        "# Теперь вы работаете в роли архивариуса РСФСР и занимаетесь хранением информации об иуществе раскулаченных граждан Имперской России\n",
        "# У вас несколько книг с записями, упорядоченных по алфавиту. Каждая книга хранит фамилии, начинающиеся с конкретной буквы.\n",
        "# Внутри книги указаны фамилии, к каждому гражданину указана категория имущества, например, мебель, посуда, картины и т.д.\n",
        "# В каждой категории указан список вещей, которые были изъяты.\n",
        "# Вы вносите записи, и если новой записи нет, вы ее создаете. Затем, когда ищите конкретную категорию предмета, начинаете перебирать все книги, начиная с первой буквы по алфавиту в вашем списке.\n",
        "# Очевидно, что вам нужно использовать defaultdict и ChainMap\n",
        "\n",
        "from collections import defaultdict, ChainMap\n",
        "\n",
        "books = {}\n",
        "for letter in 'АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ':\n",
        "    books[letter] = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "all_books = ChainMap(*[books])\n",
        "\n",
        "def add_record(surname, category, item):\n",
        "    first_letter = surname[0].upper()\n",
        "\n",
        "    if first_letter in all_books:\n",
        "        all_books[first_letter][surname][category].append(item)\n",
        "        print(f\"Добавлено: {surname} - {category} - {item}\")\n",
        "    else:\n",
        "        print(f\"Нет книги для буквы '{first_letter}'\")\n",
        "\n",
        "def find_items_by_category(category):\n",
        "    print(f\"\\nПоиск предметов категории '{category}':\")\n",
        "\n",
        "    for letter in 'АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ':\n",
        "        if letter in all_books:\n",
        "            for surname, categories in all_books[letter].items():\n",
        "                if category in categories:\n",
        "                    items = categories[category]\n",
        "                    print(f\"   {surname}: {', '.join(items)}\")\n",
        "\n",
        "add_record(\"Иванов\", \"мебель\", \"дубовый стол\")\n",
        "add_record(\"Иванов\", \"мебель\", \"кресло\")\n",
        "add_record(\"Петров\", \"картины\", \"портрет императора\")\n",
        "\n",
        "find_items_by_category(\"мебель\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0tYXeQfyxE7"
      },
      "outputs": [],
      "source": [
        "# Используя sys и os\n",
        "# Выведите некоторые ваши директории с указанием размера всех файлов и упорядочьте их (директории) по времени последнего обращения\n",
        "# Выведите список расширений файлов, которые хранятся на вашем ПК\n",
        "# Посчитайте объем памяти, который используется вашим интерпретатором\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rvyxym8yxE7"
      },
      "source": [
        "#### ДОПОЛНИТЕЛЬНЫЕ ПРАКТИЧЕСКИЕ ЗАДАЧИ\n",
        "\n",
        "Ниже представлены дополнительные задачи для закрепления изученного материала. Каждая задача использует только те концепции, которые были представлены в данном уроке.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHOkWjBoyxE7"
      },
      "source": [
        "**Задача 1: Система управления библиотекой**\n",
        "\n",
        "Создайте систему управления библиотекой используя collections:\n",
        "\n",
        "1. Создайте namedtuple `Book` с полями: title, author, isbn, year\n",
        "2. Создайте namedtuple `Reader` с полями: name, reader_id, phone\n",
        "3. Используйте `defaultdict(list)` для хранения книг по жанрам\n",
        "4. Используйте `deque` для очереди читателей, ожидающих популярную книгу\n",
        "5. Используйте `Counter` для подсчета количества книг каждого автора\n",
        "6. Используйте `OrderedDict` для хранения истории выдачи книг (читатель -> список книг)\n",
        "7. Сериализуйте все данные в JSON и pickle форматы\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH-XIhHsyxE7",
        "outputId": "6f641d55-bbff-43e4-d253-7b13657b8591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Книга 'Война и мир' выдана читателю Иван Иванов\n",
            "Книга '1984' выдана читателю Петр Петров\n",
            "Книга 'Мастер и Маргарита' выдана читателю Иван Иванов\n",
            "Читатель R003 добавлен в очередь ожидания книги 'Война и мир'\n",
            "Читатель R002 добавлен в очередь ожидания книги 'Мастер и Маргарита'\n",
            "Данные сохранены в library_data.json\n",
            "Данные сохранены в library_data.pkl\n",
            "\n",
            "СТАТИСТИКА БИБЛИОТЕКИ\n",
            "Всего книг: 5\n",
            "Всего читателей: 3\n",
            "Книг в очереди ожидания: 2\n",
            "Записей в истории выдачи: 2\n",
            "\n",
            "Книги по жанрам:\n",
            "  Роман: 4 книг\n",
            "  Антиутопия: 1 книг\n",
            "\n",
            "Топ авторов:\n",
            "  Лев Толстой: 2 книг\n",
            "  Фёдор Достоевский: 1 книг\n",
            "  Джордж Оруэлл: 1 книг\n",
            "  Михаил Булгаков: 1 книг\n",
            "\n",
            "==================================================\n",
            "Создаем новую систему и загружаем данные...\n",
            "Данные загружены из library_data.json\n",
            "\n",
            "СТАТИСТИКА БИБЛИОТЕКИ\n",
            "Всего книг: 5\n",
            "Всего читателей: 3\n",
            "Книг в очереди ожидания: 2\n",
            "Записей в истории выдачи: 2\n",
            "\n",
            "Книги по жанрам:\n",
            "  Роман: 4 книг\n",
            "  Антиутопия: 1 книг\n",
            "\n",
            "Топ авторов:\n",
            "  Лев Толстой: 2 книг\n",
            "  Фёдор Достоевский: 1 книг\n",
            "  Джордж Оруэлл: 1 книг\n",
            "  Михаил Булгаков: 1 книг\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pickle\n",
        "from collections import namedtuple, defaultdict, deque, Counter, OrderedDict\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any\n",
        "import os\n",
        "\n",
        "# namedtuple для книг и читателей\n",
        "Book = namedtuple('Book', ['title', 'author', 'isbn', 'year', 'genre'])\n",
        "Reader = namedtuple('Reader', ['name', 'reader_id', 'phone'])\n",
        "\n",
        "class LibraryManagementSystem:\n",
        "    def __init__(self):\n",
        "        # defaultdict для хранения книг по жанрам\n",
        "        self.books_by_genre = defaultdict(list)\n",
        "\n",
        "        # deque для очереди читателей, ожидающих популярную книгу\n",
        "        self.waiting_queue = deque()\n",
        "\n",
        "        # для подсчета количества книг каждого автора\n",
        "        self.books_by_author = Counter()\n",
        "\n",
        "        # для хранения истории выдачи книг\n",
        "        self.lending_history = OrderedDict()\n",
        "\n",
        "        # структуры для хранения данных\n",
        "        self.all_books = []\n",
        "        self.all_readers = []\n",
        "\n",
        "    def add_book(self, title: str, author: str, isbn: str, year: int, genre: str) -> None:\n",
        "        book = Book(title, author, isbn, year, genre)\n",
        "        self.all_books.append(book)\n",
        "        self.books_by_genre[genre].append(book)\n",
        "        self.books_by_author[author] += 1\n",
        "\n",
        "    def add_reader(self, name: str, reader_id: str, phone: str) -> None:\n",
        "        reader = Reader(name, reader_id, phone)\n",
        "        self.all_readers.append(reader)\n",
        "\n",
        "    def lend_book(self, reader_id: str, isbn: str) -> None:\n",
        "        # находим книгу и читателя\n",
        "        book = next((b for b in self.all_books if b.isbn == isbn), None)\n",
        "        reader = next((r for r in self.all_readers if r.reader_id == reader_id), None)\n",
        "\n",
        "        if book and reader:\n",
        "            # добавляем в историю выдачи\n",
        "            if reader_id not in self.lending_history:\n",
        "                self.lending_history[reader_id] = []\n",
        "            self.lending_history[reader_id].append({\n",
        "                'book_isbn': isbn,\n",
        "                'book_title': book.title,\n",
        "                'lend_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            })\n",
        "            print(f\"Книга '{book.title}' выдана читателю {reader.name}\")\n",
        "        else:\n",
        "            print(\"Книга или читатель не найдены\")\n",
        "\n",
        "    def add_to_waiting_queue(self, reader_id: str, book_title: str) -> None:\n",
        "        self.waiting_queue.append({\n",
        "            'reader_id': reader_id,\n",
        "            'book_title': book_title,\n",
        "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        })\n",
        "        print(f\"Читатель {reader_id} добавлен в очередь ожидания книги '{book_title}'\")\n",
        "\n",
        "    def get_next_in_queue(self) -> Dict[str, str]:\n",
        "        if self.waiting_queue:\n",
        "            return self.waiting_queue.popleft()\n",
        "        return None\n",
        "\n",
        "    def get_books_by_genre(self, genre: str) -> List[Book]:\n",
        "        return self.books_by_genre.get(genre, [])\n",
        "\n",
        "    def get_author_stats(self) -> Dict[str, int]:\n",
        "        return dict(self.books_by_author)\n",
        "\n",
        "    def get_lending_history(self) -> OrderedDict:\n",
        "        return self.lending_history\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            'books': [book._asdict() for book in self.all_books],\n",
        "            'readers': [reader._asdict() for reader in self.all_readers],\n",
        "            'books_by_genre': {\n",
        "                genre: [book._asdict() for book in books]\n",
        "                for genre, books in self.books_by_genre.items()\n",
        "            },\n",
        "            'waiting_queue': list(self.waiting_queue),\n",
        "            'books_by_author': dict(self.books_by_author),\n",
        "            'lending_history': {\n",
        "                reader_id: history\n",
        "                for reader_id, history in self.lending_history.items()\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def from_dict(self, data: Dict[str, Any]) -> None:\n",
        "        # очищаем текущие данные\n",
        "        self.__init__()\n",
        "\n",
        "        # загружаем книги\n",
        "        for book_data in data.get('books', []):\n",
        "            self.add_book(**book_data)\n",
        "\n",
        "        # загружаем читателей\n",
        "        for reader_data in data.get('readers', []):\n",
        "            self.add_reader(**reader_data)\n",
        "\n",
        "        # загружаем историю выдачи\n",
        "        for reader_id, history in data.get('lending_history', {}).items():\n",
        "            self.lending_history[reader_id] = history\n",
        "\n",
        "        # загружаем очередь ожидания\n",
        "        self.waiting_queue.extend(data.get('waiting_queue', []))\n",
        "\n",
        "    def save_to_json(self, filename: str) -> None:\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Данные сохранены в {filename}\")\n",
        "\n",
        "    def load_from_json(self, filename: str) -> None:\n",
        "        if os.path.exists(filename):\n",
        "            with open(filename, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "            self.from_dict(data)\n",
        "            print(f\"Данные загружены из {filename}\")\n",
        "        else:\n",
        "            print(f\"Файл {filename} не существует\")\n",
        "\n",
        "    def save_to_pickle(self, filename: str) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(self.to_dict(), f)\n",
        "        print(f\"Данные сохранены в {filename}\")\n",
        "\n",
        "    def load_from_pickle(self, filename: str) -> None:\n",
        "        if os.path.exists(filename):\n",
        "            with open(filename, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "            self.from_dict(data)\n",
        "            print(f\"Данные загружены из {filename}\")\n",
        "        else:\n",
        "            print(f\"Файл {filename} не существует\")\n",
        "\n",
        "    def display_stats(self) -> None:\n",
        "        print(\"\\nСТАТИСТИКА БИБЛИОТЕКИ\")\n",
        "        print(f\"Всего книг: {len(self.all_books)}\")\n",
        "        print(f\"Всего читателей: {len(self.all_readers)}\")\n",
        "        print(f\"Книг в очереди ожидания: {len(self.waiting_queue)}\")\n",
        "        print(f\"Записей в истории выдачи: {len(self.lending_history)}\")\n",
        "\n",
        "        print(\"\\nКниги по жанрам:\")\n",
        "        for genre, books in self.books_by_genre.items():\n",
        "            print(f\"  {genre}: {len(books)} книг\")\n",
        "\n",
        "        print(\"\\nТоп авторов:\")\n",
        "        for author, count in self.books_by_author.most_common(5):\n",
        "            print(f\"  {author}: {count} книг\")\n",
        "\n",
        "library = LibraryManagementSystem()\n",
        "\n",
        "library.add_book(\"Война и мир\", \"Лев Толстой\", \"978-5-389-07464-0\", 1869, \"Роман\")\n",
        "library.add_book(\"Анна Каренина\", \"Лев Толстой\", \"978-5-389-07465-7\", 1877, \"Роман\")\n",
        "library.add_book(\"Преступление и наказание\", \"Фёдор Достоевский\", \"978-5-389-07466-4\", 1866, \"Роман\")\n",
        "library.add_book(\"1984\", \"Джордж Оруэлл\", \"978-5-389-07467-1\", 1949, \"Антиутопия\")\n",
        "library.add_book(\"Мастер и Маргарита\", \"Михаил Булгаков\", \"978-5-389-07468-8\", 1967, \"Роман\")\n",
        "\n",
        "library.add_reader(\"Иван Иванов\", \"R001\", \"+7-999-123-45-67\")\n",
        "library.add_reader(\"Петр Петров\", \"R002\", \"+7-999-987-65-43\")\n",
        "library.add_reader(\"Мария Сидорова\", \"R003\", \"+7-999-555-44-33\")\n",
        "\n",
        "library.lend_book(\"R001\", \"978-5-389-07464-0\")\n",
        "library.lend_book(\"R002\", \"978-5-389-07467-1\")\n",
        "library.lend_book(\"R001\", \"978-5-389-07468-8\")\n",
        "\n",
        "library.add_to_waiting_queue(\"R003\", \"Война и мир\")\n",
        "library.add_to_waiting_queue(\"R002\", \"Мастер и Маргарита\")\n",
        "\n",
        "library.save_to_json('library_data.json')\n",
        "library.save_to_pickle('library_data.pkl')\n",
        "\n",
        "library.display_stats()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Создаем новую систему и загружаем данные...\")\n",
        "\n",
        "new_library = LibraryManagementSystem()\n",
        "new_library.load_from_json('library_data.json')\n",
        "new_library.display_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHwXTr8qyxE7"
      },
      "source": [
        "**Задача 2: Анализатор файловой системы**\n",
        "\n",
        "Создайте анализатор файловой системы используя os и sys:\n",
        "\n",
        "1. Создайте namedtuple `FileInfo` с полями: name, size, extension, modified_time\n",
        "2. Используйте `os.walk()` для обхода директории\n",
        "3. Используйте `os.path` функции для получения информации о файлах\n",
        "4. Используйте `Counter` для подсчета файлов по расширениям\n",
        "5. Используйте `defaultdict(list)` для группировки файлов по размеру (маленькие < 1MB, средние 1-100MB, большие > 100MB)\n",
        "6. Используйте `deque` для хранения последних 10 найденных файлов\n",
        "7. Выведите статистику используя `sys.getsizeof()` для подсчета памяти\n",
        "8. Сохраните результаты в JSON файл\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LpCs_L6HyxE7",
        "outputId": "9c9be3b7-be04-4ef4-d8bf-377f7a3f7095"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Введите путь для анализа:  C:\\Users\\hunte\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Анализ завершен. Результаты сохранены в filesystem_analysis.json\n",
            "Найдено расширений: 423\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from collections import namedtuple, Counter, defaultdict, deque\n",
        "from datetime import datetime\n",
        "\n",
        "# namedtuple для информации о файле\n",
        "FileInfo = namedtuple('FileInfo', ['name', 'size', 'extension', 'modified_time'])\n",
        "\n",
        "def analyze_filesystem(directory):\n",
        "    # os.walk для обхода директории\n",
        "    file_counter = Counter()\n",
        "    size_groups = defaultdict(list)\n",
        "    recent_files = deque(maxlen=10)  # deque для последних 10 файлов\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            # os.path для получения информации\n",
        "            if os.path.isfile(file_path):\n",
        "                size = os.path.getsize(file_path)\n",
        "                ext = os.path.splitext(file)[1].lower() or 'no_extension'\n",
        "                mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
        "\n",
        "                file_info = FileInfo(file, size, ext, mod_time)\n",
        "\n",
        "                # для расширений\n",
        "                file_counter[ext] += 1\n",
        "\n",
        "                # для группировки по размеру\n",
        "                if size < 1024 * 1024:  # < 1MB\n",
        "                    size_groups['small'].append(file_info)\n",
        "                elif size < 100 * 1024 * 1024:  # 1-100MB\n",
        "                    size_groups['medium'].append(file_info)\n",
        "                else:  # > 100MB\n",
        "                    size_groups['large'].append(file_info)\n",
        "\n",
        "                # добавляем в deque последних файлов\n",
        "                recent_files.append(file_info)\n",
        "\n",
        "    # подсчет памяти\n",
        "    memory_usage = {\n",
        "        'file_counter': sys.getsizeof(file_counter),\n",
        "        'size_groups': sys.getsizeof(size_groups),\n",
        "        'recent_files': sys.getsizeof(recent_files)\n",
        "    }\n",
        "\n",
        "    # подготовка данных для JSON\n",
        "    result = {\n",
        "        'extensions': dict(file_counter),\n",
        "        'size_groups': {\n",
        "            group: [file._asdict() for file in files]\n",
        "            for group, files in size_groups.items()\n",
        "        },\n",
        "        'recent_files': [file._asdict() for file in recent_files],\n",
        "        'memory_usage': memory_usage\n",
        "    }\n",
        "\n",
        "    # сохранение в JSON\n",
        "    with open('filesystem_analysis.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(result, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    directory_to_scan = input(\"Введите путь для анализа: \") or \".\"\n",
        "    result = analyze_filesystem(directory_to_scan)\n",
        "    print(f\"Анализ завершен. Результаты сохранены в filesystem_analysis.json\")\n",
        "    print(f\"Найдено расширений: {len(result['extensions'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxL0lj6FyxE7"
      },
      "source": [
        "**Задача 3: Система конфигурации приложения**\n",
        "\n",
        "Создайте систему конфигурации используя ChainMap и defaultdict:\n",
        "\n",
        "1. Создайте namedtuple `Config` с полями: key, value, section, default_value\n",
        "2. Создайте несколько словарей конфигурации (default, user, environment)\n",
        "3. Используйте `ChainMap` для объединения конфигураций с приоритетом\n",
        "4. Используйте `defaultdict(dict)` для группировки настроек по секциям\n",
        "5. Используйте `OrderedDict` для сохранения порядка загрузки конфигураций\n",
        "6. Используйте `os.environ` для чтения переменных окружения\n",
        "7. Сериализуйте конфигурацию в JSON и pickle форматы\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwVYksG5yxE7",
        "outputId": "2c76ee23-2616-4971-9dff-f5858f0399cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Host: 192.168.1.100\n",
            "Port: 3306\n",
            "Debug: false\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from collections import namedtuple, ChainMap, defaultdict, OrderedDict\n",
        "\n",
        "# namedtuple\n",
        "Config = namedtuple('Config', ['key', 'value', 'section', 'default_value'])\n",
        "\n",
        "class ConfigurationSystem:\n",
        "    def __init__(self):\n",
        "        # словари конфигурации\n",
        "        self.default_config = {}\n",
        "        self.user_config = {}\n",
        "        self.environment_config = {}\n",
        "\n",
        "        # для объединения с приоритетом (последний имеет высший приоритет)\n",
        "        self.chain = ChainMap(self.environment_config, self.user_config, self.default_config)\n",
        "\n",
        "        # для группировки по секциям\n",
        "        self.section_config = defaultdict(dict)\n",
        "\n",
        "        # для порядка загрузки\n",
        "        self.load_order = OrderedDict()\n",
        "\n",
        "    def add_config(self, key: str, value: str, section: str = 'general', default_value: str = None):\n",
        "        config = Config(key, value, section, default_value)\n",
        "\n",
        "        # добавляем в default config\n",
        "        self.default_config[key] = config\n",
        "\n",
        "        # группируем по секциям\n",
        "        self.section_config[section][key] = config\n",
        "\n",
        "        # запоминаем порядок\n",
        "        self.load_order[key] = config\n",
        "\n",
        "    def set_user_config(self, key: str, value: str):\n",
        "        if key in self.default_config:\n",
        "            config = self.default_config[key]._replace(value=value)\n",
        "            self.user_config[key] = config\n",
        "            self.section_config[config.section][key] = config\n",
        "\n",
        "    def load_environment_variables(self, prefix: str = \"APP_\"):\n",
        "        for env_key, env_value in os.environ.items():\n",
        "            if env_key.startswith(prefix):\n",
        "                config_key = env_key[len(prefix):].lower()\n",
        "                if config_key in self.default_config:\n",
        "                    config = self.default_config[config_key]._replace(value=env_value)\n",
        "                    self.environment_config[config_key] = config\n",
        "                    self.section_config[config.section][config_key] = config\n",
        "\n",
        "    def get(self, key: str):\n",
        "        return self.chain[key].value if key in self.chain else None\n",
        "\n",
        "    def get_section(self, section: str):\n",
        "        return dict(self.section_config[section])\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'default_config': {k: v._asdict() for k, v in self.default_config.items()},\n",
        "            'user_config': {k: v._asdict() for k, v in self.user_config.items()},\n",
        "            'environment_config': {k: v._asdict() for k, v in self.environment_config.items()},\n",
        "            'section_config': {\n",
        "                section: {k: v._asdict() for k, v in configs.items()}\n",
        "                for section, configs in self.section_config.items()\n",
        "            },\n",
        "            'load_order': {k: v._asdict() for k, v in self.load_order.items()}\n",
        "        }\n",
        "\n",
        "    def save_to_json(self, filename: str):\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def save_to_pickle(self, filename: str):\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(self.to_dict(), f)\n",
        "\n",
        "    def load_from_json(self, filename: str):\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            self._from_dict(data)\n",
        "\n",
        "    def load_from_pickle(self, filename: str):\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self._from_dict(data)\n",
        "\n",
        "    def _from_dict(self, data: dict):\n",
        "        self.default_config = {k: Config(**v) for k, v in data['default_config'].items()}\n",
        "        self.user_config = {k: Config(**v) for k, v in data['user_config'].items()}\n",
        "        self.environment_config = {k: Config(**v) for k, v in data['environment_config'].items()}\n",
        "        self.section_config = defaultdict(dict, {\n",
        "            section: {k: Config(**v) for k, v in configs.items()}\n",
        "            for section, configs in data['section_config'].items()\n",
        "        })\n",
        "        self.load_order = OrderedDict({k: Config(**v) for k, v in data['load_order'].items()})\n",
        "        self.chain = ChainMap(self.environment_config, self.user_config, self.default_config)\n",
        "\n",
        "config_system = ConfigurationSystem()\n",
        "\n",
        "config_system.add_config('host', 'localhost', 'database', '127.0.0.1')\n",
        "config_system.add_config('port', '5432', 'database', '5432')\n",
        "config_system.add_config('debug', 'false', 'general', 'false')\n",
        "config_system.add_config('log_level', 'info', 'logging', 'info')\n",
        "\n",
        "config_system.set_user_config('host', '192.168.1.100')\n",
        "config_system.set_user_config('log_level', 'debug')\n",
        "\n",
        "os.environ['APP_PORT'] = '3306'\n",
        "config_system.load_environment_variables()\n",
        "\n",
        "print(\"Host:\", config_system.get('host'))  # user_config\n",
        "print(\"Port:\", config_system.get('port'))  # environment_config\n",
        "print(\"Debug:\", config_system.get('debug'))  # default_config\n",
        "\n",
        "config_system.save_to_json('config.json')\n",
        "config_system.save_to_pickle('config.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRe3Mkl1yxE7"
      },
      "source": [
        "**Задача 4: Мониторинг системы**\n",
        "\n",
        "Создайте систему мониторинга используя sys и os:\n",
        "\n",
        "1. Создайте namedtuple `SystemInfo` с полями: cpu_count, memory_usage, process_id, user_name\n",
        "2. Используйте `os.cpu_count()` для получения количества процессоров\n",
        "3. Используйте `sys.getallocatedblocks()` для мониторинга памяти\n",
        "4. Используйте `os.getpid()` и `os.getlogin()` для информации о процессе\n",
        "5. Используйте `deque` для хранения последних 20 измерений\n",
        "6. Используйте `Counter` для подсчета частоты использования различных функций\n",
        "7. Используйте `defaultdict(list)` для группировки измерений по времени\n",
        "8. Сохраните историю мониторинга в pickle файл\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "from collections import namedtuple, deque, Counter, defaultdict\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "SystemInfo = namedtuple('SystemInfo', ['cpu_count', 'memory_usage', 'process_id', 'user_name'])\n",
        "\n",
        "class SystemMonitor:\n",
        "    def __init__(self):\n",
        "        self.measurements = deque(maxlen=20)\n",
        "        self.function_counter = Counter()\n",
        "        self.time_grouped_data = defaultdict(list)\n",
        "\n",
        "    def collect_system_info(self):\n",
        "        self.function_counter['collect_system_info'] += 1\n",
        "\n",
        "        cpu_count = os.cpu_count()\n",
        "        memory_usage = sys.getallocatedblocks()\n",
        "        process_id = os.getpid()\n",
        "\n",
        "        try:\n",
        "            user_name = os.getlogin()\n",
        "        except OSError:\n",
        "            user_name = os.environ.get('USER', 'unknown')\n",
        "\n",
        "        info = SystemInfo(cpu_count, memory_usage, process_id, user_name)\n",
        "        timestamp = datetime.now()\n",
        "\n",
        "        self.measurements.append((timestamp, info))\n",
        "        self.time_grouped_data[timestamp.strftime(\"%Y-%m-%d %H:%M\")].append(info)\n",
        "\n",
        "        return info\n",
        "\n",
        "    def save_history(self, filename='monitoring_history.pkl'):\n",
        "        history = {\n",
        "            'measurements': list(self.measurements),\n",
        "            'function_stats': self.function_counter,\n",
        "            'time_grouped_data': dict(self.time_grouped_data)\n",
        "        }\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(history, f)\n",
        "\n",
        "monitor = SystemMonitor()\n",
        "\n",
        "for _ in range(25):\n",
        "    monitor.collect_system_info()\n",
        "\n",
        "monitor.save_history()\n",
        "\n",
        "print(f\"последние {len(monitor.measurements)} измерений:\")\n",
        "for timestamp, info in monitor.measurements:\n",
        "    print(f\"{timestamp}: CPU={info.cpu_count}, Memory={info.memory_usage}\")\n",
        "\n",
        "print(f\"\\nстатистика вызовов: {monitor.function_counter}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M7g7ukpzC2w",
        "outputId": "113b4585-c6fb-4af3-bd39-7c5ff278e13b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "последние 20 измерений:\n",
            "2025-10-03 06:41:03.582147: CPU=2, Memory=523570\n",
            "2025-10-03 06:41:03.582204: CPU=2, Memory=523575\n",
            "2025-10-03 06:41:03.582260: CPU=2, Memory=523581\n",
            "2025-10-03 06:41:03.582315: CPU=2, Memory=523586\n",
            "2025-10-03 06:41:03.582405: CPU=2, Memory=523591\n",
            "2025-10-03 06:41:03.582472: CPU=2, Memory=523596\n",
            "2025-10-03 06:41:03.582530: CPU=2, Memory=523601\n",
            "2025-10-03 06:41:03.582586: CPU=2, Memory=523606\n",
            "2025-10-03 06:41:03.582642: CPU=2, Memory=523612\n",
            "2025-10-03 06:41:03.582697: CPU=2, Memory=523617\n",
            "2025-10-03 06:41:03.582753: CPU=2, Memory=523623\n",
            "2025-10-03 06:41:03.582820: CPU=2, Memory=523629\n",
            "2025-10-03 06:41:03.582880: CPU=2, Memory=523634\n",
            "2025-10-03 06:41:03.582935: CPU=2, Memory=523639\n",
            "2025-10-03 06:41:03.582991: CPU=2, Memory=523645\n",
            "2025-10-03 06:41:03.583049: CPU=2, Memory=523649\n",
            "2025-10-03 06:41:03.583105: CPU=2, Memory=523653\n",
            "2025-10-03 06:41:03.583161: CPU=2, Memory=523656\n",
            "2025-10-03 06:41:03.583218: CPU=2, Memory=523659\n",
            "2025-10-03 06:41:03.583273: CPU=2, Memory=523662\n",
            "\n",
            "статистика вызовов: Counter({'collect_system_info': 25})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WapNPlvRyxE8"
      },
      "source": [
        "**Задача 5: Система логирования**\n",
        "\n",
        "Создайте систему логирования используя все изученные коллекции:\n",
        "\n",
        "1. Создайте namedtuple `LogEntry` с полями: timestamp, level, message, module, function\n",
        "2. Используйте `deque` для хранения последних 100 логов (кольцевой буфер)\n",
        "3. Используйте `defaultdict(list)` для группировки логов по уровням (DEBUG, INFO, WARNING, ERROR)\n",
        "4. Используйте `Counter` для подсчета количества логов каждого уровня\n",
        "5. Используйте `OrderedDict` для хранения логов по времени (FIFO)\n",
        "6. Используйте `ChainMap` для объединения различных источников логов\n",
        "7. Используйте `os.path` для работы с файлами логов\n",
        "8. Сериализуйте логи в JSON и pickle форматы\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import os\n",
        "from collections import namedtuple, deque, defaultdict, Counter, OrderedDict, ChainMap\n",
        "from datetime import datetime\n",
        "\n",
        "LogEntry = namedtuple('LogEntry', ['timestamp', 'level', 'message', 'module', 'function'])\n",
        "\n",
        "class Logger:\n",
        "    def __init__(self):\n",
        "        self.log_buffer = deque(maxlen=100)\n",
        "        self.logs_by_level = defaultdict(list)\n",
        "        self.log_counter = Counter()\n",
        "        self.ordered_logs = OrderedDict()\n",
        "        self.log_sources = ChainMap({})\n",
        "\n",
        "    def log(self, level, message, module, function):\n",
        "        timestamp = datetime.now()\n",
        "        entry = LogEntry(timestamp, level, message, module, function)\n",
        "\n",
        "        self.log_buffer.append(entry)\n",
        "        self.logs_by_level[level].append(entry)\n",
        "        self.log_counter[level] += 1\n",
        "        self.ordered_logs[timestamp] = entry\n",
        "\n",
        "        return entry\n",
        "\n",
        "    def add_log_source(self, source_name, logs):\n",
        "        self.log_sources = self.log_sources.new_child({source_name: logs})\n",
        "\n",
        "    def save_json(self, filename='logs.json'):\n",
        "        def convert_entry(entry):\n",
        "            return {\n",
        "                'timestamp': entry.timestamp.isoformat(),\n",
        "                'level': entry.level,\n",
        "                'message': entry.message,\n",
        "                'module': entry.module,\n",
        "                'function': entry.function\n",
        "            }\n",
        "\n",
        "        logs_data = {\n",
        "            'buffer': [convert_entry(entry) for entry in self.log_buffer],\n",
        "            'by_level': {level: [convert_entry(entry) for entry in entries]\n",
        "                        for level, entries in self.logs_by_level.items()},\n",
        "            'counts': dict(self.log_counter),\n",
        "            'ordered': {ts.isoformat(): convert_entry(entry)\n",
        "                       for ts, entry in self.ordered_logs.items()}\n",
        "        }\n",
        "\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(logs_data, f, indent=2)\n",
        "\n",
        "    def save_pickle(self, filename='logs.pkl'):\n",
        "        data = {\n",
        "            'buffer': self.log_buffer,\n",
        "            'by_level': self.logs_by_level,\n",
        "            'counts': self.log_counter,\n",
        "            'ordered': self.ordered_logs,\n",
        "            'sources': dict(self.log_sources)\n",
        "        }\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "logger = Logger()\n",
        "\n",
        "logger.log('INFO', 'система запущена', 'main', 'run')\n",
        "logger.log('DEBUG', 'инициализация компонентов', 'app', 'init')\n",
        "logger.log('WARNING', 'низкая память', 'system', 'check_memory')\n",
        "logger.log('ERROR', 'ошибка подключения', 'network', 'connect')\n",
        "\n",
        "external_logs = [LogEntry(datetime.now(), 'INFO', 'внешний лог', 'external', 'process')]\n",
        "logger.add_log_source('external_system', external_logs)\n",
        "\n",
        "logger.save_json()\n",
        "logger.save_pickle()\n",
        "\n",
        "print(f\"всего логов: {sum(logger.log_counter.values())}\")\n",
        "print(f\"распределение по уровням: {dict(logger.log_counter)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XrTXtpnzpuq",
        "outputId": "91d96c66-2c56-49bf-f0a8-198c3fc7e631"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "всего логов: 4\n",
            "распределение по уровням: {'INFO': 1, 'DEBUG': 1, 'WARNING': 1, 'ERROR': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ykugX5cyxE8"
      },
      "source": [
        "**Задача 6: Кэш-система**\n",
        "\n",
        "Создайте простую кэш-систему используя collections:\n",
        "\n",
        "1. Создайте namedtuple `CacheEntry` с полями: key, value, timestamp, access_count\n",
        "2. Используйте `OrderedDict` для реализации LRU (Least Recently Used) кэша\n",
        "3. Используйте `deque` для хранения истории доступа к ключам\n",
        "4. Используйте `Counter` для подсчета частоты доступа к каждому ключу\n",
        "5. Используйте `defaultdict(int)` для хранения счетчиков доступа\n",
        "6. Реализуйте методы: get, set, delete, clear, size\n",
        "7. Используйте `sys.getsizeof()` для мониторинга размера кэша\n",
        "8. Сериализуйте кэш в pickle формат для сохранения между сессиями\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pickle\n",
        "from collections import namedtuple, OrderedDict, deque, Counter, defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "CacheEntry = namedtuple('CacheEntry', ['key', 'value', 'timestamp', 'access_count'])\n",
        "\n",
        "class Cache:\n",
        "    def __init__(self, max_size=100):\n",
        "        self.cache = OrderedDict()\n",
        "        self.access_history = deque(maxlen=1000)\n",
        "        self.access_frequency = Counter()\n",
        "        self.access_counters = defaultdict(int)\n",
        "        self.max_size = max_size\n",
        "\n",
        "    def get(self, key):\n",
        "        if key in self.cache:\n",
        "            entry = self.cache[key]\n",
        "            self.cache.move_to_end(key)\n",
        "\n",
        "            updated_entry = CacheEntry(\n",
        "                key=entry.key,\n",
        "                value=entry.value,\n",
        "                timestamp=entry.timestamp,\n",
        "                access_count=entry.access_count + 1\n",
        "            )\n",
        "            self.cache[key] = updated_entry\n",
        "\n",
        "            self.access_history.append((datetime.now(), key, 'get'))\n",
        "            self.access_frequency[key] += 1\n",
        "            self.access_counters[key] += 1\n",
        "\n",
        "            return updated_entry.value\n",
        "        return None\n",
        "\n",
        "    def set(self, key, value):\n",
        "        if len(self.cache) >= self.max_size:\n",
        "            self._evict()\n",
        "\n",
        "        entry = CacheEntry(\n",
        "            key=key,\n",
        "            value=value,\n",
        "            timestamp=datetime.now(),\n",
        "            access_count=0\n",
        "        )\n",
        "        self.cache[key] = entry\n",
        "        self.cache.move_to_end(key)\n",
        "\n",
        "        self.access_history.append((datetime.now(), key, 'set'))\n",
        "        self.access_frequency[key] += 1\n",
        "        self.access_counters[key] = 0\n",
        "\n",
        "    def delete(self, key):\n",
        "        if key in self.cache:\n",
        "            del self.cache[key]\n",
        "            self.access_history.append((datetime.now(), key, 'delete'))\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def clear(self):\n",
        "        self.cache.clear()\n",
        "        self.access_history.clear()\n",
        "        self.access_frequency.clear()\n",
        "        self.access_counters.clear()\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.cache)\n",
        "\n",
        "    def _evict(self):\n",
        "        if self.cache:\n",
        "            oldest_key = next(iter(self.cache))\n",
        "            del self.cache[oldest_key]\n",
        "\n",
        "    def get_cache_size(self):\n",
        "        total_size = 0\n",
        "        for entry in self.cache.values():\n",
        "            total_size += sys.getsizeof(entry.key)\n",
        "            total_size += sys.getsizeof(entry.value)\n",
        "            total_size += sys.getsizeof(entry)\n",
        "        return total_size\n",
        "\n",
        "    def save_cache(self, filename='cache.pkl'):\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'cache': dict(self.cache),\n",
        "                'access_history': list(self.access_history),\n",
        "                'access_frequency': dict(self.access_frequency),\n",
        "                'access_counters': dict(self.access_counters)\n",
        "            }, f)\n",
        "\n",
        "    def load_cache(self, filename='cache.pkl'):\n",
        "        try:\n",
        "            with open(filename, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "                self.cache = OrderedDict(data['cache'])\n",
        "                self.access_history = deque(data['access_history'], maxlen=1000)\n",
        "                self.access_frequency = Counter(data['access_frequency'])\n",
        "                self.access_counters = defaultdict(int, data['access_counters'])\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "\n",
        "cache = Cache(max_size=5)\n",
        "\n",
        "for i in range(10):\n",
        "    cache.set(f'key{i}', f'value{i}')\n",
        "\n",
        "cache.get('key5')\n",
        "cache.get('key6')\n",
        "cache.get('key5')\n",
        "\n",
        "print(f\"размер кэша: {cache.size()}\")\n",
        "print(f\"размер в памяти: {cache.get_cache_size()} байт\")\n",
        "print(f\"частота доступа: {dict(cache.access_frequency.most_common(3))}\")\n",
        "\n",
        "cache.save_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SheZUDuA0TkX",
        "outputId": "e1df3abc-bc17-4887-d49b-3bdc7ffd8d4e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "размер кэша: 5\n",
            "размер в памяти: 820 байт\n",
            "частота доступа: {'key5': 3, 'key6': 2, 'key0': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdkzHHn6yxE8"
      },
      "source": [
        "**Задача 7: Анализатор текста**\n",
        "\n",
        "Создайте анализатор текста используя collections:\n",
        "\n",
        "1. Создайте namedtuple `WordInfo` с полями: word, frequency, length, first_occurrence\n",
        "2. Используйте `Counter` для подсчета частоты слов\n",
        "3. Используйте `defaultdict(list)` для группировки слов по длине\n",
        "4. Используйте `deque` для хранения последних 50 уникальных слов\n",
        "5. Используйте `OrderedDict` для хранения слов в порядке первого появления\n",
        "6. Используйте `os.path` для работы с текстовыми файлами\n",
        "7. Используйте `sys.getsizeof()` для анализа памяти\n",
        "8. Сохраните результаты анализа в JSON файл\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from collections import namedtuple, Counter, defaultdict, deque, OrderedDict\n",
        "import re\n",
        "\n",
        "WordInfo = namedtuple('WordInfo', ['word', 'frequency', 'length', 'first_occurrence'])\n",
        "\n",
        "class TextAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.word_frequency = Counter()\n",
        "        self.words_by_length = defaultdict(list)\n",
        "        self.recent_words = deque(maxlen=50)\n",
        "        self.first_occurrence = OrderedDict()\n",
        "        self.position_counter = 0\n",
        "\n",
        "    def analyze_text(self, text):\n",
        "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "        for word in words:\n",
        "            self.position_counter += 1\n",
        "\n",
        "            self.word_frequency[word] += 1\n",
        "\n",
        "            self.words_by_length[len(word)].append(word)\n",
        "\n",
        "            if word not in self.first_occurrence:\n",
        "                self.first_occurrence[word] = self.position_counter\n",
        "                if word not in self.recent_words:\n",
        "                    self.recent_words.append(word)\n",
        "\n",
        "    def analyze_file(self, filename):\n",
        "        if os.path.exists(filename):\n",
        "            with open(filename, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                self.analyze_text(text)\n",
        "\n",
        "    def get_word_info(self, word):\n",
        "        if word in self.word_frequency:\n",
        "            return WordInfo(\n",
        "                word=word,\n",
        "                frequency=self.word_frequency[word],\n",
        "                length=len(word),\n",
        "                first_occurrence=self.first_occurrence[word]\n",
        "            )\n",
        "        return None\n",
        "\n",
        "    def get_memory_usage(self):\n",
        "        return {\n",
        "            'word_frequency': sys.getsizeof(self.word_frequency),\n",
        "            'words_by_length': sys.getsizeof(self.words_by_length),\n",
        "            'recent_words': sys.getsizeof(self.recent_words),\n",
        "            'first_occurrence': sys.getsizeof(self.first_occurrence)\n",
        "        }\n",
        "\n",
        "    def save_results(self, filename='analysis.json'):\n",
        "        results = {\n",
        "            'most_common_words': self.word_frequency.most_common(10),\n",
        "            'words_by_length': {length: words[:10] for length, words in self.words_by_length.items()},\n",
        "            'recent_words': list(self.recent_words),\n",
        "            'first_occurrence': dict(list(self.first_occurrence.items())[:20]),\n",
        "            'memory_usage': self.get_memory_usage(),\n",
        "            'total_unique_words': len(self.word_frequency),\n",
        "            'total_words': sum(self.word_frequency.values())\n",
        "        }\n",
        "\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "analyzer = TextAnalyzer()\n",
        "\n",
        "sample_text = \"\"\"\n",
        "Это пример текста для анализа. Текст содержит несколько слов разной длины.\n",
        "Некоторые слова повторяются несколько раз в этом тексте для демонстрации частоты.\n",
        "Анализ текста помогает понять структуру и содержание документа.\n",
        "\"\"\"\n",
        "\n",
        "analyzer.analyze_text(sample_text)\n",
        "analyzer.analyze_text(\"дополнительный текст с новыми и повторяющимися словами\")\n",
        "\n",
        "print(f\"уникальных слов: {len(analyzer.word_frequency)}\")\n",
        "print(f\"всего слов: {sum(analyzer.word_frequency.values())}\")\n",
        "print(f\"последние слова: {list(analyzer.recent_words)}\")\n",
        "\n",
        "analyzer.save_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgFfNgUV1Ty_",
        "outputId": "1fff2c76-a9e2-4b95-8741-38841d63bfdc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "уникальных слов: 32\n",
            "всего слов: 37\n",
            "последние слова: ['это', 'пример', 'текста', 'для', 'анализа', 'текст', 'содержит', 'несколько', 'слов', 'разной', 'длины', 'некоторые', 'слова', 'повторяются', 'раз', 'в', 'этом', 'тексте', 'демонстрации', 'частоты', 'анализ', 'помогает', 'понять', 'структуру', 'и', 'содержание', 'документа', 'дополнительный', 'с', 'новыми', 'повторяющимися', 'словами']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmddJ15SyxE8"
      },
      "source": [
        "**Задача 8: Система управления задачами**\n",
        "\n",
        "Создайте систему управления задачами (TODO) используя все изученные концепции:\n",
        "\n",
        "1. Создайте namedtuple `Task` с полями: id, title, description, priority, status, created_date\n",
        "2. Используйте `defaultdict(list)` для группировки задач по статусу (todo, in_progress, done)\n",
        "3. Используйте `deque` для очереди задач с высоким приоритетом\n",
        "4. Используйте `Counter` для подсчета задач по приоритету\n",
        "5. Используйте `OrderedDict` для хранения задач в порядке создания\n",
        "6. Используйте `ChainMap` для объединения различных списков задач\n",
        "7. Используйте `os.path` для работы с файлами задач\n",
        "8. Реализуйте функции: add_task, complete_task, get_tasks_by_status, get_priority_queue\n",
        "9. Сериализуйте все данные в JSON и pickle форматы\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import os\n",
        "from collections import namedtuple, defaultdict, deque, Counter, OrderedDict, ChainMap\n",
        "from datetime import datetime\n",
        "\n",
        "Task = namedtuple('Task', ['id', 'title', 'description', 'priority', 'status', 'created_date'])\n",
        "\n",
        "class TaskManager:\n",
        "    def __init__(self):\n",
        "        self.tasks_by_status = defaultdict(list)\n",
        "        self.priority_queue = deque()\n",
        "        self.priority_counter = Counter()\n",
        "        self.ordered_tasks = OrderedDict()\n",
        "        self.task_sources = ChainMap({})\n",
        "        self.next_id = 1\n",
        "\n",
        "    def add_task(self, title, description, priority=1):\n",
        "        task_id = self.next_id\n",
        "        self.next_id += 1\n",
        "\n",
        "        task = Task(\n",
        "            id=task_id,\n",
        "            title=title,\n",
        "            description=description,\n",
        "            priority=priority,\n",
        "            status='todo',\n",
        "            created_date=datetime.now()\n",
        "        )\n",
        "\n",
        "        self.tasks_by_status['todo'].append(task)\n",
        "        if priority >= 3:\n",
        "            self.priority_queue.append(task)\n",
        "        self.priority_counter[priority] += 1\n",
        "        self.ordered_tasks[task_id] = task\n",
        "\n",
        "        return task\n",
        "\n",
        "    def complete_task(self, task_id):\n",
        "        if task_id in self.ordered_tasks:\n",
        "            task = self.ordered_tasks[task_id]\n",
        "\n",
        "            self.tasks_by_status[task.status].remove(task)\n",
        "            self.tasks_by_status['done'].append(task)\n",
        "\n",
        "            updated_task = task._replace(status='done')\n",
        "            self.ordered_tasks[task_id] = updated_task\n",
        "\n",
        "            if task in self.priority_queue:\n",
        "                self.priority_queue.remove(task)\n",
        "\n",
        "            return updated_task\n",
        "        return None\n",
        "\n",
        "    def get_tasks_by_status(self, status):\n",
        "        return self.tasks_by_status.get(status, [])\n",
        "\n",
        "    def get_priority_queue(self):\n",
        "        return list(self.priority_queue)\n",
        "\n",
        "    def add_task_source(self, source_name, tasks):\n",
        "        self.task_sources = self.task_sources.new_child({source_name: tasks})\n",
        "\n",
        "    def save_json(self, filename='tasks.json'):\n",
        "        def convert_task(task):\n",
        "            return {\n",
        "                'id': task.id,\n",
        "                'title': task.title,\n",
        "                'description': task.description,\n",
        "                'priority': task.priority,\n",
        "                'status': task.status,\n",
        "                'created_date': task.created_date.isoformat()\n",
        "            }\n",
        "\n",
        "        tasks_data = {\n",
        "            'tasks_by_status': {status: [convert_task(task) for task in tasks]\n",
        "                               for status, tasks in self.tasks_by_status.items()},\n",
        "            'priority_queue': [convert_task(task) for task in self.priority_queue],\n",
        "            'priority_counts': dict(self.priority_counter),\n",
        "            'ordered_tasks': {task_id: convert_task(task)\n",
        "                             for task_id, task in self.ordered_tasks.items()},\n",
        "            'next_id': self.next_id\n",
        "        }\n",
        "\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(tasks_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    def save_pickle(self, filename='tasks.pkl'):\n",
        "        data = {\n",
        "            'tasks_by_status': self.tasks_by_status,\n",
        "            'priority_queue': self.priority_queue,\n",
        "            'priority_counter': self.priority_counter,\n",
        "            'ordered_tasks': self.ordered_tasks,\n",
        "            'task_sources': dict(self.task_sources),\n",
        "            'next_id': self.next_id\n",
        "        }\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def load_json(self, filename='tasks.json'):\n",
        "        if os.path.exists(filename):\n",
        "            with open(filename, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "                for status, tasks in data['tasks_by_status'].items():\n",
        "                    for task_data in tasks:\n",
        "                        task = Task(\n",
        "                            id=task_data['id'],\n",
        "                            title=task_data['title'],\n",
        "                            description=task_data['description'],\n",
        "                            priority=task_data['priority'],\n",
        "                            status=task_data['status'],\n",
        "                            created_date=datetime.fromisoformat(task_data['created_date'])\n",
        "                        )\n",
        "                        self.tasks_by_status[status].append(task)\n",
        "                        self.ordered_tasks[task.id] = task\n",
        "\n",
        "                self.next_id = data['next_id']\n",
        "\n",
        "manager = TaskManager()\n",
        "\n",
        "manager.add_task(\"задача 1\", \"описание задачи 1\", 2)\n",
        "manager.add_task(\"срочная задача\", \"важная задача\", 3)\n",
        "manager.add_task(\"обычная задача\", \"простая задача\", 1)\n",
        "\n",
        "manager.complete_task(1)\n",
        "\n",
        "print(f\"задачи в работе: {len(manager.get_tasks_by_status('in_progress'))}\")\n",
        "print(f\"выполненные задачи: {len(manager.get_tasks_by_status('done'))}\")\n",
        "print(f\"очередь приоритетных: {len(manager.get_priority_queue())}\")\n",
        "\n",
        "manager.save_json()\n",
        "manager.save_pickle()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq0tBI3s3eVK",
        "outputId": "219c696b-5e74-45dd-ff23-b44595c5bf65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "задачи в работе: 0\n",
            "выполненные задачи: 1\n",
            "очередь приоритетных: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCKc4UwryxE8"
      },
      "source": [
        "**Задача 9: Система мониторинга производительности**\n",
        "\n",
        "Создайте систему мониторинга производительности используя sys и collections:\n",
        "\n",
        "1. Создайте namedtuple `PerformanceMetric` с полями: function_name, execution_time, memory_usage, timestamp\n",
        "2. Используйте `deque` для хранения последних 100 измерений производительности\n",
        "3. Используйте `defaultdict(list)` для группировки метрик по функциям\n",
        "4. Используйте `Counter` для подсчета количества вызовов каждой функции\n",
        "5. Используйте `OrderedDict` для хранения метрик в хронологическом порядке\n",
        "6. Используйте `sys.getsizeof()` для мониторинга памяти\n",
        "7. Используйте `os.path` для работы с файлами метрик\n",
        "8. Реализуйте функции: record_metric, get_function_stats, get_memory_usage, export_metrics\n",
        "9. Сериализуйте метрики в JSON и pickle форматы\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from collections import namedtuple, deque, defaultdict, Counter, OrderedDict\n",
        "from datetime import datetime\n",
        "\n",
        "PerformanceMetric = namedtuple('PerformanceMetric', ['function_name', 'execution_time', 'memory_usage', 'timestamp'])\n",
        "\n",
        "class PerformanceMonitor:\n",
        "    def __init__(self):\n",
        "        self.metrics_buffer = deque(maxlen=100)\n",
        "        self.metrics_by_function = defaultdict(list)\n",
        "        self.function_call_counter = Counter()\n",
        "        self.chronological_metrics = OrderedDict()\n",
        "\n",
        "    def record_metric(self, function_name, execution_time, memory_usage):\n",
        "        timestamp = datetime.now()\n",
        "        metric = PerformanceMetric(function_name, execution_time, memory_usage, timestamp)\n",
        "\n",
        "        self.metrics_buffer.append(metric)\n",
        "        self.metrics_by_function[function_name].append(metric)\n",
        "        self.function_call_counter[function_name] += 1\n",
        "        self.chronological_metrics[timestamp] = metric\n",
        "\n",
        "        return metric\n",
        "\n",
        "    def get_function_stats(self, function_name):\n",
        "        if function_name in self.metrics_by_function:\n",
        "            metrics = self.metrics_by_function[function_name]\n",
        "            execution_times = [m.execution_time for m in metrics]\n",
        "            memory_usages = [m.memory_usage for m in metrics]\n",
        "\n",
        "            return {\n",
        "                'call_count': len(metrics),\n",
        "                'avg_execution_time': sum(execution_times) / len(execution_times),\n",
        "                'avg_memory_usage': sum(memory_usages) / len(memory_usages),\n",
        "                'min_execution_time': min(execution_times),\n",
        "                'max_execution_time': max(execution_times)\n",
        "            }\n",
        "        return None\n",
        "\n",
        "    def get_memory_usage(self):\n",
        "        return {\n",
        "            'metrics_buffer': sys.getsizeof(self.metrics_buffer),\n",
        "            'metrics_by_function': sys.getsizeof(self.metrics_by_function),\n",
        "            'function_call_counter': sys.getsizeof(self.function_call_counter),\n",
        "            'chronological_metrics': sys.getsizeof(self.chronological_metrics)\n",
        "        }\n",
        "\n",
        "    def export_metrics(self, filename_prefix='metrics'):\n",
        "        def convert_metric(metric):\n",
        "            return {\n",
        "                'function_name': metric.function_name,\n",
        "                'execution_time': metric.execution_time,\n",
        "                'memory_usage': metric.memory_usage,\n",
        "                'timestamp': metric.timestamp.isoformat()\n",
        "            }\n",
        "\n",
        "        json_data = {\n",
        "            'metrics_buffer': [convert_metric(m) for m in self.metrics_buffer],\n",
        "            'metrics_by_function': {func: [convert_metric(m) for m in metrics]\n",
        "                                   for func, metrics in self.metrics_by_function.items()},\n",
        "            'function_call_counter': dict(self.function_call_counter),\n",
        "            'chronological_metrics': {ts.isoformat(): convert_metric(metric)\n",
        "                                     for ts, metric in self.chronological_metrics.items()},\n",
        "            'memory_usage': self.get_memory_usage()\n",
        "        }\n",
        "\n",
        "        with open(f'{filename_prefix}.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(json_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        pickle_data = {\n",
        "            'metrics_buffer': self.metrics_buffer,\n",
        "            'metrics_by_function': self.metrics_by_function,\n",
        "            'function_call_counter': self.function_call_counter,\n",
        "            'chronological_metrics': self.chronological_metrics\n",
        "        }\n",
        "\n",
        "        with open(f'{filename_prefix}.pkl', 'wb') as f:\n",
        "            pickle.dump(pickle_data, f)\n",
        "\n",
        "def monitor_function(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        start_memory = sys.getsizeof(args) + sys.getsizeof(kwargs)\n",
        "\n",
        "        result = func(*args, **kwargs)\n",
        "\n",
        "        end_time = time.time()\n",
        "        end_memory = sys.getsizeof(result)\n",
        "\n",
        "        execution_time = end_time - start_time\n",
        "        memory_usage = end_memory - start_memory\n",
        "\n",
        "        monitor.record_metric(func.__name__, execution_time, memory_usage)\n",
        "\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@monitor_function\n",
        "def example_function(n):\n",
        "    time.sleep(0.1)\n",
        "    return [i for i in range(n)]\n",
        "\n",
        "@monitor_function\n",
        "def another_function(text):\n",
        "    time.sleep(0.05)\n",
        "    return text.upper()\n",
        "\n",
        "monitor = PerformanceMonitor()\n",
        "\n",
        "for i in range(5):\n",
        "    example_function(1000)\n",
        "    another_function(\"test string\")\n",
        "\n",
        "print(f\"всего записей: {len(monitor.metrics_buffer)}\")\n",
        "print(f\"вызовы функций: {dict(monitor.function_call_counter)}\")\n",
        "\n",
        "stats = monitor.get_function_stats('example_function')\n",
        "if stats:\n",
        "    print(f\"статистика example_function: {stats}\")\n",
        "\n",
        "print(f\"использование памяти: {monitor.get_memory_usage()}\")\n",
        "\n",
        "monitor.export_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnr24Lsz3yGF",
        "outputId": "3f971386-e2d4-4717-d9b2-6e364e93a6db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "всего записей: 10\n",
            "вызовы функций: {'example_function': 5, 'another_function': 5}\n",
            "статистика example_function: {'call_count': 5, 'avg_execution_time': 0.10022220611572266, 'avg_memory_usage': 8744.0, 'min_execution_time': 0.10014867782592773, 'max_execution_time': 0.10033369064331055}\n",
            "использование памяти: {'metrics_buffer': 760, 'metrics_by_function': 192, 'function_call_counter': 200, 'chronological_metrics': 864}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUynVxIfyxE8"
      },
      "source": [
        "**Задача 10: Комплексная система управления данными**\n",
        "\n",
        "Создайте комплексную систему управления данными, объединяющую все изученные концепции:\n",
        "\n",
        "1. Создайте несколько namedtuple для различных типов данных (User, Product, Order, etc.)\n",
        "2. Используйте `defaultdict` для создания индексов по различным полям\n",
        "3. Используйте `deque` для реализации очередей обработки данных\n",
        "4. Используйте `Counter` для аналитики и статистики\n",
        "5. Используйте `OrderedDict` для хранения данных в определенном порядке\n",
        "6. Используйте `ChainMap` для объединения различных источников данных\n",
        "7. Используйте `os` и `sys` для работы с файловой системой и мониторинга\n",
        "8. Реализуйте CRUD операции (Create, Read, Update, Delete)\n",
        "9. Добавьте функции экспорта/импорта данных в различных форматах\n",
        "10. Сериализуйте все данные в JSON, pickle и другие форматы\n",
        "11. Добавьте типизацию для всех функций и классов\n",
        "12. Реализуйте систему логирования для отслеживания операций\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "from collections import namedtuple, defaultdict, deque, Counter, OrderedDict, ChainMap\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "\n",
        "User = namedtuple('User', ['id', 'name', 'email', 'created_at'])\n",
        "Product = namedtuple('Product', ['id', 'name', 'price', 'category', 'stock'])\n",
        "Order = namedtuple('Order', ['id', 'user_id', 'product_id', 'quantity', 'status', 'created_at'])\n",
        "\n",
        "class DataManager:\n",
        "    def __init__(self):\n",
        "        self.users: OrderedDict = OrderedDict()\n",
        "        self.products: OrderedDict = OrderedDict()\n",
        "        self.orders: OrderedDict = OrderedDict()\n",
        "\n",
        "        self.user_indexes = defaultdict(dict)\n",
        "        self.product_indexes = defaultdict(dict)\n",
        "        self.order_indexes = defaultdict(dict)\n",
        "\n",
        "        self.processing_queue = deque(maxlen=100)\n",
        "        self.data_sources = ChainMap({})\n",
        "\n",
        "        self.stats_counter = Counter()\n",
        "        self.operation_log = deque(maxlen=200)\n",
        "\n",
        "        self.next_ids = {'user': 1, 'product': 1, 'order': 1}\n",
        "\n",
        "    def _log_operation(self, operation: str, entity: str, entity_id: int) -> None:\n",
        "        log_entry = f\"{datetime.now()}: {operation} {entity} {entity_id}\"\n",
        "        self.operation_log.append(log_entry)\n",
        "        self.stats_counter[f\"{operation}_{entity}\"] += 1\n",
        "\n",
        "    def create_user(self, name: str, email: str) -> User:\n",
        "        user_id = self.next_ids['user']\n",
        "        self.next_ids['user'] += 1\n",
        "\n",
        "        user = User(user_id, name, email, datetime.now())\n",
        "        self.users[user_id] = user\n",
        "\n",
        "        self.user_indexes['email'][email] = user_id\n",
        "        self.user_indexes['name'][name] = user_id\n",
        "\n",
        "        self._log_operation('CREATE', 'user', user_id)\n",
        "        return user\n",
        "\n",
        "    def get_user(self, user_id: int) -> Optional[User]:\n",
        "        self._log_operation('READ', 'user', user_id)\n",
        "        return self.users.get(user_id)\n",
        "\n",
        "    def update_user(self, user_id: int, **kwargs) -> Optional[User]:\n",
        "        if user_id not in self.users:\n",
        "            return None\n",
        "\n",
        "        old_user = self.users[user_id]\n",
        "        user_dict = old_user._asdict()\n",
        "        user_dict.update(kwargs)\n",
        "\n",
        "        new_user = User(**user_dict)\n",
        "        self.users[user_id] = new_user\n",
        "\n",
        "        if 'email' in kwargs:\n",
        "            self.user_indexes['email'][kwargs['email']] = user_id\n",
        "        if 'name' in kwargs:\n",
        "            self.user_indexes['name'][kwargs['name']] = user_id\n",
        "\n",
        "        self._log_operation('UPDATE', 'user', user_id)\n",
        "        return new_user\n",
        "\n",
        "    def delete_user(self, user_id: int) -> bool:\n",
        "        if user_id in self.users:\n",
        "            user = self.users[user_id]\n",
        "            del self.users[user_id]\n",
        "\n",
        "            if user.email in self.user_indexes['email']:\n",
        "                del self.user_indexes['email'][user.email]\n",
        "            if user.name in self.user_indexes['name']:\n",
        "                del self.user_indexes['name'][user.name]\n",
        "\n",
        "            self._log_operation('DELETE', 'user', user_id)\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def create_product(self, name: str, price: float, category: str, stock: int) -> Product:\n",
        "        product_id = self.next_ids['product']\n",
        "        self.next_ids['product'] += 1\n",
        "\n",
        "        product = Product(product_id, name, price, category, stock)\n",
        "        self.products[product_id] = product\n",
        "\n",
        "        self.product_indexes['category'][category] = product_id\n",
        "        self.product_indexes['name'][name] = product_id\n",
        "\n",
        "        self._log_operation('CREATE', 'product', product_id)\n",
        "        return product\n",
        "\n",
        "    def create_order(self, user_id: int, product_id: int, quantity: int) -> Optional[Order]:\n",
        "        if user_id not in self.users or product_id not in self.products:\n",
        "            return None\n",
        "\n",
        "        order_id = self.next_ids['order']\n",
        "        self.next_ids['order'] += 1\n",
        "\n",
        "        order = Order(order_id, user_id, product_id, quantity, 'pending', datetime.now())\n",
        "        self.orders[order_id] = order\n",
        "\n",
        "        self.order_indexes['user_id'][user_id] = order_id\n",
        "        self.order_indexes['product_id'][product_id] = order_id\n",
        "        self.order_indexes['status']['pending'] = order_id\n",
        "\n",
        "        self.processing_queue.append(('process_order', order_id))\n",
        "\n",
        "        self._log_operation('CREATE', 'order', order_id)\n",
        "        return order\n",
        "\n",
        "    def get_entities_by_index(self, entity_type: str, index_field: str, value: Any) -> List:\n",
        "        if entity_type == 'user':\n",
        "            entities = self.users\n",
        "            indexes = self.user_indexes\n",
        "        elif entity_type == 'product':\n",
        "            entities = self.products\n",
        "            indexes = self.product_indexes\n",
        "        elif entity_type == 'order':\n",
        "            entities = self.orders\n",
        "            indexes = self.order_indexes\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "        if value in indexes[index_field]:\n",
        "            entity_id = indexes[index_field][value]\n",
        "            return [entities[entity_id]]\n",
        "        return []\n",
        "\n",
        "    def add_data_source(self, source_name: str, data: Dict) -> None:\n",
        "        self.data_sources = self.data_sources.new_child({source_name: data})\n",
        "\n",
        "    def get_memory_usage(self) -> Dict[str, int]:\n",
        "        return {\n",
        "            'users': sys.getsizeof(self.users),\n",
        "            'products': sys.getsizeof(self.products),\n",
        "            'orders': sys.getsizeof(self.orders),\n",
        "            'indexes': sys.getsizeof(self.user_indexes) + sys.getsizeof(self.product_indexes) + sys.getsizeof(self.order_indexes),\n",
        "            'queue': sys.getsizeof(self.processing_queue),\n",
        "            'logs': sys.getsizeof(self.operation_log)\n",
        "        }\n",
        "\n",
        "    def export_data(self, format_type: str = 'json') -> None:\n",
        "        if format_type == 'json':\n",
        "            def convert_entity(entity):\n",
        "                data = entity._asdict()\n",
        "                for key, value in data.items():\n",
        "                    if isinstance(value, datetime):\n",
        "                        data[key] = value.isoformat()\n",
        "                return data\n",
        "\n",
        "            data = {\n",
        "                'users': [convert_entity(user) for user in self.users.values()],\n",
        "                'products': [convert_entity(product) for product in self.products.values()],\n",
        "                'orders': [convert_entity(order) for order in self.orders.values()],\n",
        "                'stats': dict(self.stats_counter),\n",
        "                'logs': list(self.operation_log)\n",
        "            }\n",
        "\n",
        "            with open('data_export.json', 'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        elif format_type == 'pickle':\n",
        "            data = {\n",
        "                'users': self.users,\n",
        "                'products': self.products,\n",
        "                'orders': self.orders,\n",
        "                'indexes': dict(self.user_indexes),\n",
        "                'stats': self.stats_counter,\n",
        "                'next_ids': self.next_ids\n",
        "            }\n",
        "\n",
        "            with open('data_export.pkl', 'wb') as f:\n",
        "                pickle.dump(data, f)\n",
        "\n",
        "    def import_data(self, format_type: str = 'json') -> None:\n",
        "        if format_type == 'json' and os.path.exists('data_export.json'):\n",
        "            with open('data_export.json', 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "                for user_data in data['users']:\n",
        "                    user_data['created_at'] = datetime.fromisoformat(user_data['created_at'])\n",
        "                    user = User(**user_data)\n",
        "                    self.users[user.id] = user\n",
        "\n",
        "                for product_data in data['products']:\n",
        "                    product = Product(**product_data)\n",
        "                    self.products[product.id] = product\n",
        "\n",
        "                for order_data in data['orders']:\n",
        "                    order_data['created_at'] = datetime.fromisoformat(order_data['created_at'])\n",
        "                    order = Order(**order_data)\n",
        "                    self.orders[order.id] = order\n",
        "\n",
        "manager = DataManager()\n",
        "\n",
        "user1 = manager.create_user(\"иван иванов\", \"ivan@mail.com\")\n",
        "user2 = manager.create_user(\"петр петров\", \"petr@mail.com\")\n",
        "\n",
        "product1 = manager.create_product(\"ноутбук\", 50000.0, \"электроника\", 10)\n",
        "product2 = manager.create_product(\"книга\", 500.0, \"литература\", 100)\n",
        "\n",
        "order1 = manager.create_order(user1.id, product1.id, 1)\n",
        "order2 = manager.create_order(user2.id, product2.id, 2)\n",
        "\n",
        "print(f\"всего пользователей: {len(manager.users)}\")\n",
        "print(f\"всего товаров: {len(manager.products)}\")\n",
        "print(f\"всего заказов: {len(manager.orders)}\")\n",
        "print(f\"статистика операций: {dict(manager.stats_counter)}\")\n",
        "print(f\"использование памяти: {manager.get_memory_usage()}\")\n",
        "\n",
        "manager.export_data('json')\n",
        "manager.export_data('pickle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CNlVl454Py5",
        "outputId": "cb371142-9d79-4e9e-d16c-491f2fb74409"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "всего пользователей: 2\n",
            "всего товаров: 2\n",
            "всего заказов: 2\n",
            "статистика операций: {'CREATE_user': 2, 'CREATE_product': 2, 'CREATE_order': 2}\n",
            "использование памяти: {'users': 416, 'products': 416, 'orders': 416, 'indexes': 576, 'queue': 760, 'logs': 760}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qi1HeTMyxE8"
      },
      "source": [
        "#### РЕКОМЕНДАЦИИ ПО ВЫПОЛНЕНИЮ ЗАДАЧ\n",
        "\n",
        "1. **Начните с простых задач** (1-3) для понимания базовых концепций\n",
        "2. **Используйте типизацию** - добавляйте type hints для всех функций и переменных\n",
        "3. **Структурируйте код** - разбивайте задачи на логические функции и классы\n",
        "4. **Документируйте код** - добавляйте docstrings для всех функций\n",
        "5. **Тестируйте сериализацию** - убедитесь, что данные корректно сохраняются и загружаются\n",
        "6. **Обрабатывайте ошибки** - используйте try-except блоки для обработки исключений\n",
        "7. **Оптимизируйте память** - используйте `sys.getsizeof()` для мониторинга использования памяти\n",
        "8. **Следуйте принципам** - код должен быть читаемым, понятным и структурированным\n",
        "\n",
        "**Дополнительные требования:**\n",
        "- Все объекты должны быть сериализованы в соответствующие форматы\n",
        "- Код должен содержать комментарии на русском языке\n",
        "- Функции должны быть небольшими и выполнять одну задачу\n",
        "- Используйте только те библиотеки и концепции, которые представлены в уроке\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXTlOYSVyxE8",
        "outputId": "231bd23e-b568-4fdf-ebac-7533cb5bca13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x =  0.00\n",
            "  Точное значение: 1.0000000000\n",
            "  Приближение:     1.0000000000\n",
            "  Итераций:        2\n",
            "--------------------------------------------------\n",
            "x =  0.50\n",
            "  Точное значение: 1.2247448714\n",
            "  Приближение:     1.2247448714\n",
            "  Итераций:        26\n",
            "--------------------------------------------------\n",
            "x =  1.00\n",
            "  Точное значение: 1.4142135624\n",
            "  Приближение:     1.4142135624\n",
            "  Итераций:        1996476\n",
            "--------------------------------------------------\n",
            "x = -0.50\n",
            "  Точное значение: 0.7071067812\n",
            "  Приближение:     0.7071067812\n",
            "  Итераций:        26\n",
            "--------------------------------------------------\n",
            "x =  0.25\n",
            "  Точное значение: 1.1180339887\n",
            "  Приближение:     1.1180339888\n",
            "  Итераций:        14\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "def sqrt1_plus_x_taylor(x, epsilon=1e-10):\n",
        "\n",
        "    # проверка области сходимости ряда\n",
        "    if abs(x) > 1:\n",
        "        raise ValueError(\"сходится только при |x| <= 1\")\n",
        "\n",
        "    def _iter():\n",
        "        n = 0\n",
        "        current_term = 1.0\n",
        "\n",
        "        while True:\n",
        "            yield current_term\n",
        "            n += 1\n",
        "            current_term = current_term * ((0.5 - (n - 1)) / n) * x\n",
        "\n",
        "    total = 0.0\n",
        "    prev_total = 0.0\n",
        "    iterations = 0\n",
        "\n",
        "    for term in _iter():\n",
        "        total += term\n",
        "        iterations += 1\n",
        "\n",
        "        # проверяем точность\n",
        "        if abs(total - prev_total) < epsilon:\n",
        "            break\n",
        "        prev_total = total\n",
        "\n",
        "    return total, iterations\n",
        "\n",
        "test_values = [0.0, 0.5, 1.0, -0.5, 0.25]\n",
        "\n",
        "for x in test_values:\n",
        "    approx, iters = sqrt1_plus_x_taylor(x)\n",
        "    exact = math.sqrt(1 + x)\n",
        "\n",
        "    print(f\"x = {x:5.2f}\")\n",
        "    print(f\"  Точное значение: {exact:.10f}\")\n",
        "    print(f\"  Приближение:     {approx:.10f}\")\n",
        "    print(f\"  Итераций:        {iters}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVbUkWBAyxE8",
        "outputId": "1e854805-7b2f-430e-c722-bde4e361d555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x =  0.00\n",
            "  Точное значение: 1.0000000000\n",
            "  Приближение:     1.0000000000\n",
            "  Итераций:        2\n",
            "--------------------------------------------------\n",
            "x =  0.50\n",
            "  Точное значение: 1.2247448714\n",
            "  Приближение:     1.2247448714\n",
            "  Итераций:        26\n",
            "--------------------------------------------------\n",
            "x =  1.00\n",
            "  Точное значение: 1.4142135624\n",
            "  Приближение:     1.4142135624\n",
            "  Итераций:        1996476\n",
            "--------------------------------------------------\n",
            "x = -0.50\n",
            "  Точное значение: 0.7071067812\n",
            "  Приближение:     0.7071067812\n",
            "  Итераций:        26\n",
            "--------------------------------------------------\n",
            "x =  0.25\n",
            "  Точное значение: 1.1180339887\n",
            "  Приближение:     1.1180339888\n",
            "  Итераций:        14\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from typing import Generator\n",
        "\n",
        "def taylor_gen(x: float) -> Generator[float, None, None]:\n",
        "    n: int = 0\n",
        "    current_term: int = 1.0\n",
        "\n",
        "    while True:\n",
        "        yield current_term\n",
        "        n += 1\n",
        "        current_term = current_term * ((0.5 - (n - 1)) / n) * x\n",
        "\n",
        "def sqrt1_plus_x_taylor(x: float, epsilon: float = 1e-10) -> tuple[float, int]:\n",
        "\n",
        "    if abs(x) > 1:\n",
        "        raise ValueError(\"сходится только при |x| <= 1\")\n",
        "\n",
        "    total = 0.0\n",
        "    prev_total = 0.0\n",
        "    iterations = 0\n",
        "\n",
        "    # создаем генератор\n",
        "    generator = taylor_gen(x)\n",
        "\n",
        "    while True:\n",
        "        # получаем следующий член ряда\n",
        "        term = next(generator)\n",
        "        total += term\n",
        "        iterations += 1\n",
        "\n",
        "        # проверяем точность\n",
        "        if abs(total - prev_total) < epsilon:\n",
        "            break\n",
        "        prev_total = total\n",
        "\n",
        "    return total, iterations\n",
        "\n",
        "test_values = [0.0, 0.5, 1.0, -0.5, 0.25]\n",
        "\n",
        "for x in test_values:\n",
        "    approx, iters = sqrt1_plus_x_taylor(x)\n",
        "    exact = math.sqrt(1 + x)\n",
        "\n",
        "    print(f\"x = {x:5.2f}\")\n",
        "    print(f\"  Точное значение: {exact:.10f}\")\n",
        "    print(f\"  Приближение:     {approx:.10f}\")\n",
        "    print(f\"  Итераций:        {iters}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UycYpI6yxE9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}